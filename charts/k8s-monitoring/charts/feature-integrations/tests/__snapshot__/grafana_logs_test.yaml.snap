should add the grafana processing stage to the logs config:
  1: |
    |-
      declare "grafana_integration" {
        argument "metrics_destinations" {
          comment = "Must be a list of metric destinations where collected metrics should be forwarded to"
        }

        declare "grafana_integration_discovery" {
          argument "namespaces" {
            comment = "The namespaces to look for targets in (default: [] is all namespaces)"
            optional = true
          }

          argument "field_selectors" {
            comment = "The field selectors to use to find matching targets (default: [])"
            optional = true
          }

          argument "label_selectors" {
            comment = "The label selectors to use to find matching targets (default: [\"app.kubernetes.io/name=grafana\"])"
            optional = true
          }

          argument "port_name" {
            comment = "The of the port to scrape metrics from (default: grafana)"
            optional = true
          }

          // grafana service discovery for all of the pods
          discovery.kubernetes "grafana_pods" {
            role = "pod"

            selectors {
              role = "pod"
              field = string.join(coalesce(argument.field_selectors.value, []), ",")
              label = string.join(coalesce(argument.label_selectors.value, ["app.kubernetes.io/name=grafana"]), ",")
            }

            namespaces {
              names = coalesce(argument.namespaces.value, [])
            }

          }

          // grafana relabelings (pre-scrape)
          discovery.relabel "grafana_pods" {
            targets = discovery.kubernetes.grafana_pods.targets

            // keep only the specified metrics port name, and pods that are Running and ready
            rule {
              source_labels = [
                "__meta_kubernetes_pod_container_port_name",
                "__meta_kubernetes_pod_phase",
                "__meta_kubernetes_pod_ready",
                "__meta_kubernetes_pod_container_init",
              ]
              separator = "@"
              regex = coalesce(argument.port_name.value, "grafana") + "@Running@true@false"
              action = "keep"
            }



            rule {
              source_labels = ["__meta_kubernetes_namespace"]
              target_label  = "namespace"
            }

            rule {
              source_labels = ["__meta_kubernetes_pod_name"]
              target_label  = "pod"
            }

            rule {
              source_labels = ["__meta_kubernetes_pod_container_name"]
              target_label  = "container"
            }

            // set the workload to the controller kind and name
            rule {
              action = "lowercase"
              source_labels = ["__meta_kubernetes_pod_controller_kind"]
              target_label  = "workload_type"
            }

            rule {
              source_labels = ["__meta_kubernetes_pod_controller_name"]
              target_label  = "workload"
            }

            // remove the hash from the ReplicaSet
            rule {
              source_labels = [
                "workload_type",
                "workload",
              ]
              separator = "/"
              regex = "replicaset/(.+)-.+$"
              target_label  = "workload"
            }

            // set the app name if specified as metadata labels "app:" or "app.kubernetes.io/name:" or "k8s-app:"
            rule {
              action = "replace"
              source_labels = [
                "__meta_kubernetes_pod_label_app_kubernetes_io_name",
                "__meta_kubernetes_pod_label_k8s_app",
                "__meta_kubernetes_pod_label_app",
              ]
              separator = ";"
              regex = "^(?:;*)?([^;]+).*$"
              replacement = "$1"
              target_label = "app"
            }

            // set the component if specified as metadata labels "component:" or "app.kubernetes.io/component:" or "k8s-component:"
            rule {
              action = "replace"
              source_labels = [
                "__meta_kubernetes_pod_label_app_kubernetes_io_component",
                "__meta_kubernetes_pod_label_k8s_component",
                "__meta_kubernetes_pod_label_component",
              ]
              regex = "^(?:;*)?([^;]+).*$"
              replacement = "$1"
              target_label = "component"
            }

            // set a source label
            rule {
              action = "replace"
              replacement = "kubernetes"
              target_label = "source"
            }

          }

          export "output" {
            value = discovery.relabel.grafana_pods.output
          }
        }

        declare "grafana_integration_scrape" {
          argument "targets" {
            comment = "Must be a list() of targets"
          }

          argument "forward_to" {
            comment = "Must be a list(MetricsReceiver) where collected metrics should be forwarded to"
          }

          argument "job_label" {
            comment = "The job label to add for all Grafana metrics (default: integrations/grafana)"
            optional = true
          }

          argument "keep_metrics" {
            comment = "A regular expression of metrics to keep (default: see below)"
            optional = true
          }

          argument "drop_metrics" {
            comment = "A regular expression of metrics to drop (default: see below)"
            optional = true
          }

          argument "scrape_interval" {
            comment = "How often to scrape metrics from the targets (default: 60s)"
            optional = true
          }

          argument "max_cache_size" {
            comment = "The maximum number of elements to hold in the relabeling cache (default: 100000).  This should be at least 2x-5x your largest scrape target or samples appended rate."
            optional = true
          }

          argument "clustering" {
            comment = "Whether or not clustering should be enabled (default: false)"
            optional = true
          }

          prometheus.scrape "grafana" {
            job_name = coalesce(argument.job_label.value, "integrations/grafana")
            forward_to = [prometheus.relabel.grafana.receiver]
            targets = argument.targets.value
            scrape_interval = coalesce(argument.scrape_interval.value, "60s")

            clustering {
              enabled = coalesce(argument.clustering.value, false)
            }
          }

          // grafana metric relabelings (post-scrape)
          prometheus.relabel "grafana" {
            forward_to = argument.forward_to.value
            max_cache_size = coalesce(argument.max_cache_size.value, 100000)

            // drop metrics that match the drop_metrics regex
            rule {
              source_labels = ["__name__"]
              regex = coalesce(argument.drop_metrics.value, "")
              action = "drop"
            }

            // keep only metrics that match the keep_metrics regex
            rule {
              source_labels = ["__name__"]
              regex = coalesce(argument.keep_metrics.value, "(.+)")
              action = "keep"
            }

            // the grafana-mixin expects the instance label to be the node name
            rule {
              source_labels = ["node"]
              target_label = "instance"
              replacement = "$1"
            }
            rule {
              action = "labeldrop"
              regex = "node"
            }
          }
        }

        grafana_integration_discovery "grafana" {
          namespaces = []
          label_selectors = ["app.kubernetes.io/name=grafana"]
          port_name = "grafana"
        }

        grafana_integration_scrape  "grafana" {
          targets = grafana_integration_discovery.grafana.output
          job_label = "integrations/grafana"
          clustering = true
          scrape_interval = "60s"
          max_cache_size = 100000
          forward_to = argument.metrics_destinations.value
        }
      }
