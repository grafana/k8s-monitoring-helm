should create the MySQL config:
  1: |
    |-
      declare "mysql_integration" {
        argument "metrics_destinations" {
          comment = "Must be a list of metric destinations where collected metrics should be forwarded to"
        }


        remote.kubernetes.secret "my_database" {
          name      = "my-database-release-name-feature-integrations"
          namespace = "NAMESPACE"
        }

        prometheus.exporter.mysql "my_database" {
          data_source_name = string.format("%s:%s@(%s:%d)/",
            convert.nonsensitive(remote.kubernetes.secret.my_database.data["username"]),
            convert.nonsensitive(remote.kubernetes.secret.my_database.data["password"]),
            "my-db.mysql.svc",
            3306,
          )
          enable_collectors = ["heartbeat","mysql.user"]
        }
        prometheus.scrape "my_database" {
          targets    = prometheus.exporter.mysql.my_database.targets
          job_name   = "integration/mysql"
          forward_to = [prometheus.relabel.my_database.receiver]
        }

        prometheus.relabel "my_database" {
          max_cache_size = 100000
          rule {
            target_label = "instance"
            replacement = "my-database"
          }
          forward_to = argument.metrics_destinations.value
        }
      }
works when referencing the MySQL Secret:
  1: |
    |-
      declare "mysql_integration" {
        argument "metrics_destinations" {
          comment = "Must be a list of metric destinations where collected metrics should be forwarded to"
        }


        remote.kubernetes.secret "test_database" {
          name      = "test-database-mysql"
          namespace = "mysql"
        }

        prometheus.exporter.mysql "test_database" {
          data_source_name = string.format("%s:%s@(%s:%d)/",
            sys.env(MYSQL_ROOT_USER),
            convert.nonsensitive(remote.kubernetes.secret.test_database.data["mysql-root-password"]),
            "test-database-mysql.mysql.svc",
            3306,
          )
          enable_collectors = ["heartbeat","mysql.user"]
        }
        prometheus.scrape "test_database" {
          targets    = prometheus.exporter.mysql.test_database.targets
          job_name   = "integration/mysql"
          forward_to = [prometheus.relabel.test_database.receiver]
        }

        prometheus.relabel "test_database" {
          max_cache_size = 100000
          rule {
            target_label = "instance"
            replacement = "test-database"
          }
          forward_to = argument.metrics_destinations.value
        }
      }
works with multiple MySQL Instances:
  1: |
    |-
      declare "mysql_integration" {
        argument "metrics_destinations" {
          comment = "Must be a list of metric destinations where collected metrics should be forwarded to"
        }

        prometheus.exporter.mysql "test_db" {
          data_source_name = string.format("%s:%d/", "database.test.svc", 3306)
          enable_collectors = ["heartbeat","mysql.user"]
        }
        prometheus.scrape "test_db" {
          targets    = prometheus.exporter.mysql.test_db.targets
          job_name   = "integration/mysql"
          forward_to = [prometheus.relabel.test_db.receiver]
        }

        prometheus.relabel "test_db" {
          max_cache_size = 100000
          rule {
            target_label = "instance"
            replacement = "test-db"
          }
          forward_to = argument.metrics_destinations.value
        }

        prometheus.exporter.mysql "staging_db" {
          data_source_name  = "root:password@database.staging.svc:3306/"
          enable_collectors = ["heartbeat","mysql.user"]
        }
        prometheus.scrape "staging_db" {
          targets    = prometheus.exporter.mysql.staging_db.targets
          job_name   = "integration/mysql"
          forward_to = [prometheus.relabel.staging_db.receiver]
        }

        prometheus.relabel "staging_db" {
          max_cache_size = 100000
          rule {
            target_label = "instance"
            replacement = "staging-db"
          }
          forward_to = argument.metrics_destinations.value
        }


        remote.kubernetes.secret "prod_db" {
          name      = "prod-db-release-name-feature-integrations"
          namespace = "NAMESPACE"
        }

        prometheus.exporter.mysql "prod_db" {
          data_source_name = string.format("%s:%s@(%s:%d)/",
            convert.nonsensitive(remote.kubernetes.secret.prod_db.data["username"]),
            convert.nonsensitive(remote.kubernetes.secret.prod_db.data["password"]),
            "database.prod.svc",
            3306,
          )
          enable_collectors = ["heartbeat","mysql.user"]
        }
        prometheus.scrape "prod_db" {
          targets    = prometheus.exporter.mysql.prod_db.targets
          job_name   = "integration/mysql"
          forward_to = [prometheus.relabel.prod_db.receiver]
        }

        prometheus.relabel "prod_db" {
          max_cache_size = 100000
          rule {
            target_label = "instance"
            replacement = "prod-db"
          }
          forward_to = argument.metrics_destinations.value
        }
      }
