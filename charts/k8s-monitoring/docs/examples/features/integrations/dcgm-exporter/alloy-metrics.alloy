declare "dcgm_exporter_integration" {
  argument "metrics_destinations" {
    comment = "Must be a list of metric destinations where collected metrics should be forwarded to"
  }

  declare "dcgm_exporter_integration_discovery" {
    argument "namespaces" {
      comment = "The namespaces to look for targets in (default: [] is all namespaces)"
      optional = true
    }

    argument "field_selectors" {
      comment = "The field selectors to use to find matching targets (default: [])"
      optional = true
    }

    argument "label_selectors" {
      comment = "The label selectors to use to find matching targets (default: [\"app=nvidia-dcgm-exporter\"])"
      optional = true
    }

    argument "port_name" {
      comment = "The of the port to scrape metrics from (default: metrics)"
      optional = true
    }

    // DCGM Exporter service discovery for all of the pods
    discovery.kubernetes "dcgm_exporter_pods" {
      role = "pod"

      selectors {
        role = "pod"
        field = string.join(coalesce(argument.field_selectors.value, []), ",")
        label = string.join(coalesce(argument.label_selectors.value, ["app=nvidia-dcgm-exporter"]), ",")
      }

      namespaces {
        names = coalesce(argument.namespaces.value, [])
      }

    }

    // DCGM Exporter relabelings (pre-scrape)
    discovery.relabel "dcgm_exporter_pods" {
      targets = discovery.kubernetes.dcgm_exporter_pods.targets

      // keep only the specified metrics port name, and pods that are Running and ready
      rule {
        source_labels = [
          "__meta_kubernetes_pod_container_port_name",
          "__meta_kubernetes_pod_phase",
          "__meta_kubernetes_pod_ready",
          "__meta_kubernetes_pod_container_init",
        ]
        separator = "@"
        regex = coalesce(argument.port_name.value, "metrics") + "@Running@true@false"
        action = "keep"
      }

      rule {
        source_labels = ["__meta_kubernetes_namespace"]
        target_label  = "namespace"
      }

      rule {
        source_labels = ["__meta_kubernetes_pod_name"]
        target_label  = "pod"
      }

      rule {
        source_labels = ["__meta_kubernetes_pod_container_name"]
        target_label  = "container"
      }

      // set the workload to the controller kind and name
      rule {
        action = "lowercase"
        source_labels = ["__meta_kubernetes_pod_controller_kind"]
        target_label  = "workload_type"
      }

      rule {
        source_labels = ["__meta_kubernetes_pod_controller_name"]
        target_label  = "workload"
      }

      // remove the hash from the ReplicaSet
      rule {
        source_labels = [
          "workload_type",
          "workload",
        ]
        separator = "/"
        regex = "replicaset/(.+)-.+$"
        target_label  = "workload"
      }

      // set the app name if specified as metadata labels "app:" or "app.kubernetes.io/name:" or "k8s-app:"
      rule {
        action = "replace"
        source_labels = [
          "__meta_kubernetes_pod_label_app_kubernetes_io_name",
          "__meta_kubernetes_pod_label_k8s_app",
          "__meta_kubernetes_pod_label_app",
        ]
        separator = ";"
        regex = "^(?:;*)?([^;]+).*$"
        replacement = "$1"
        target_label = "app"
      }

      // set the component if specified as metadata labels "component:" or "app.kubernetes.io/component:" or "k8s-component:"
      rule {
        action = "replace"
        source_labels = [
          "__meta_kubernetes_pod_label_app_kubernetes_io_component",
          "__meta_kubernetes_pod_label_k8s_component",
          "__meta_kubernetes_pod_label_component",
        ]
        regex = "^(?:;*)?([^;]+).*$"
        replacement = "$1"
        target_label = "component"
      }

      // set a source label
      rule {
        action = "replace"
        replacement = "kubernetes"
        target_label = "source"
      }

    }

    export "output" {
      value = discovery.relabel.dcgm_exporter_pods.output
    }
  }

  declare "dcgm_exporter_integration_scrape" {
    argument "targets" {
      comment = "Must be a list() of targets"
    }

    argument "forward_to" {
      comment = "Must be a list(MetricsReceiver) where collected metrics should be forwarded to"
    }

    argument "job_label" {
      comment = "The job label to add for all Alloy metrics (default: integrations/dcgm-exporter)"
      optional = true
    }

    argument "keep_metrics" {
      comment = "A regular expression of metrics to keep (default: see below)"
      optional = true
    }

    argument "drop_metrics" {
      comment = "A regular expression of metrics to drop (default: see below)"
      optional = true
    }

    argument "scrape_interval" {
      comment = "How often to scrape metrics from the targets (default: 60s)"
      optional = true
    }

    argument "scrape_protocols" {
      comment = "The scrape protocols to use for scraping metrics"
      optional = true
    }

    argument "scrape_classic_histograms" {
      comment = "Whether to scrape classic histograms (default: false)."
      optional = true
    }

    argument "max_cache_size" {
      comment = "The maximum number of elements to hold in the relabeling cache (default: 100000).  This should be at least 2x-5x your largest scrape target or samples appended rate."
      optional = true
    }

    argument "clustering" {
      comment = "Whether or not clustering should be enabled (default: false)"
      optional = true
    }

    prometheus.scrape "dcgm_exporter" {
      job_name = coalesce(argument.job_label.value, "integrations/alloy")
      forward_to = [prometheus.relabel.alloy.receiver]
      targets = argument.targets.value
      scrape_interval = coalesce(argument.scrape_interval.value, "60s")
      scrape_protocols = argument.scrape_protocols.value
      scrape_classic_histograms = argument.scrape_classic_histograms.value

      clustering {
        enabled = coalesce(argument.clustering.value, false)
      }
    }

    // DCGM Exporter metric relabelings (post-scrape)
    prometheus.relabel "dcgm_exporter" {
      forward_to = argument.forward_to.value
      max_cache_size = coalesce(argument.max_cache_size.value, 100000)

      // drop metrics that match the drop_metrics regex
      rule {
        source_labels = ["__name__"]
        regex = coalesce(argument.drop_metrics.value, "")
        action = "drop"
      }

      // keep only metrics that match the keep_metrics regex
      rule {
        source_labels = ["__name__"]
        regex = coalesce(argument.keep_metrics.value, ".*")
        action = "keep"
      }

      // remove the component_id label from any metric that starts with log_bytes or log_lines, these are custom metrics that are generated
      // as part of the log annotation modules in this repo
      rule {
        action = "replace"
        source_labels = ["__name__"]
        regex = "^log_(bytes|lines).+"
        replacement = ""
        target_label = "component_id"
      }

      // set the namespace label to that of the exported_namespace
      rule {
        action = "replace"
        source_labels = ["__name__", "exported_namespace"]
        separator = "@"
        regex = "^log_(bytes|lines).+@(.+)"
        replacement = "$2"
        target_label = "namespace"
      }

      // set the pod label to that of the exported_pod
      rule {
        action = "replace"
        source_labels = ["__name__", "exported_pod"]
        separator = "@"
        regex = "^log_(bytes|lines).+@(.+)"
        replacement = "$2"
        target_label = "pod"
      }

      // set the container label to that of the exported_container
      rule {
        action = "replace"
        source_labels = ["__name__", "exported_container"]
        separator = "@"
        regex = "^log_(bytes|lines).+@(.+)"
        replacement = "$2"
        target_label = "container"
      }

      // set the job label to that of the exported_job
      rule {
        action = "replace"
        source_labels = ["__name__", "exported_job"]
        separator = "@"
        regex = "^log_(bytes|lines).+@(.+)"
        replacement = "$2"
        target_label = "job"
      }

      // set the instance label to that of the exported_instance
      rule {
        action = "replace"
        source_labels = ["__name__", "exported_instance"]
        separator = "@"
        regex = "^log_(bytes|lines).+@(.+)"
        replacement = "$2"
        target_label = "instance"
      }

      rule {
        action = "labeldrop"
        regex = "exported_(namespace|pod|container|job|instance)"
      }
    }
  }

  dcgm_exporter_integration_discovery "dcgm_exporter" {
    port_name = "metrics"
    label_selectors = ["app=nvidia-dcgm-exporter"]
  }

  dcgm_exporter_integration_scrape  "dcgm_exporter" {
    targets = dcgm_exporter_integration_discovery.dcgm_exporter.output
    job_label = "integrations/dcgm-exporter"
    clustering = true
    scrape_interval = "60s"
    scrape_protocols = ["OpenMetricsText1.0.0","OpenMetricsText0.0.1","PrometheusText0.0.4"]
    scrape_classic_histograms = false
    max_cache_size = 100000
    forward_to = argument.metrics_destinations.value
  }
}
dcgm_exporter_integration "integration" {
  metrics_destinations = [
    prometheus.remote_write.prometheus.receiver,
  ]
}
// Self Reporting
prometheus.exporter.unix "kubernetes_monitoring_telemetry" {
  set_collectors = ["textfile"]
  textfile {
    directory = "/etc/alloy"
  }
}

discovery.relabel "kubernetes_monitoring_telemetry" {
  targets = prometheus.exporter.unix.kubernetes_monitoring_telemetry.targets
  rule {
    target_label = "instance"
    action = "replace"
    replacement = "k8smon"
  }
  rule {
    target_label = "job"
    action = "replace"
    replacement = "integrations/kubernetes/kubernetes_monitoring_telemetry"
  }
}

prometheus.scrape "kubernetes_monitoring_telemetry" {
  job_name   = "integrations/kubernetes/kubernetes_monitoring_telemetry"
  targets    = discovery.relabel.kubernetes_monitoring_telemetry.output
  scrape_interval = "60s"
  clustering {
    enabled = true
  }
  forward_to = [prometheus.relabel.kubernetes_monitoring_telemetry.receiver]
}

prometheus.relabel "kubernetes_monitoring_telemetry" {
  rule {
    source_labels = ["__name__"]
    regex = "grafana_kubernetes_monitoring_.*"
    action = "keep"
  }
  forward_to = [
    prometheus.remote_write.prometheus.receiver,
  ]
}




// Destination: prometheus (prometheus)
otelcol.exporter.prometheus "prometheus" {
  add_metric_suffixes = true
  resource_to_telemetry_conversion = false
  forward_to = [prometheus.remote_write.prometheus.receiver]
}

prometheus.remote_write "prometheus" {
  endpoint {
    url = "http://prometheus.prometheus.svc:9090/api/v1/write"
    headers = {
    }
    tls_config {
      insecure_skip_verify = false
    }
    send_native_histograms = false

    queue_config {
      capacity = 10000
      min_shards = 1
      max_shards = 50
      max_samples_per_send = 2000
      batch_send_deadline = "5s"
      min_backoff = "30ms"
      max_backoff = "5s"
      retry_on_http_429 = true
      sample_age_limit = "0s"
    }

    write_relabel_config {
      source_labels = ["cluster"]
      regex = ""
      replacement = "dcgm-exporter-integration-cluster"
      target_label = "cluster"
    }
    write_relabel_config {
      source_labels = ["k8s_cluster_name"]
      regex = ""
      replacement = "dcgm-exporter-integration-cluster"
      target_label = "k8s_cluster_name"
    }
  }

  wal {
    truncate_frequency = "2h"
    min_keepalive_time = "5m"
    max_keepalive_time = "8h"
  }
}

