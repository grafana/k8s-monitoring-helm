declare "cert_manager_integration" {
  argument "metrics_destinations" {
    comment = "Must be a list of metric destinations where collected metrics should be forwarded to"
  }

  discovery.kubernetes "cert_manager" {
    role = "pod"

    selectors {
      role = "pod"
      label = "app.kubernetes.io/name=cert-manager"
    }
  }

  discovery.relabel "cert_manager" {
    targets = discovery.kubernetes.cert_manager.targets

    // keep only the specified metrics port name, and pods that are Running and ready
    rule {
      source_labels = [
        "__meta_kubernetes_pod_container_port_name",
        "__meta_kubernetes_pod_phase",
        "__meta_kubernetes_pod_ready",
      ]
      separator = "@"
      regex = "http-metrics@Running@true"
      action = "keep"
    }

    // drop any init containers
    rule {
      source_labels = ["__meta_kubernetes_pod_container_init"]
      regex = "true"
      action = "drop"
    }

    // set the namespace label
    rule {
      source_labels = ["__meta_kubernetes_namespace"]
      target_label  = "namespace"
    }

    // set the pod label
    rule {
      source_labels = ["__meta_kubernetes_pod_name"]
      target_label  = "pod"
    }

    // set the container label
    rule {
      source_labels = ["__meta_kubernetes_pod_container_name"]
      target_label  = "container"
    }

    // set a workload label
    rule {
      source_labels = [
        "__meta_kubernetes_pod_controller_kind",
        "__meta_kubernetes_pod_controller_name",
      ]
      separator = "/"
      target_label  = "workload"
    }
    // remove the hash from the ReplicaSet
    rule {
      source_labels = ["workload"]
      regex = "(ReplicaSet/.+)-.+"
      target_label  = "workload"
    }

    // set the app name if specified as metadata labels "app:" or "app.kubernetes.io/name:" or "k8s-app:"
    rule {
      action = "replace"
      source_labels = [
        "__meta_kubernetes_pod_label_app_kubernetes_io_name",
        "__meta_kubernetes_pod_label_k8s_app",
        "__meta_kubernetes_pod_label_app",
      ]
      separator = ";"
      regex = "^(?:;*)?([^;]+).*$"
      replacement = "$1"
      target_label = "app"
    }

    // set the component if specified as metadata labels "component:" or "app.kubernetes.io/component:" or "k8s-component:"
    rule {
      action = "replace"
      source_labels = [
        "__meta_kubernetes_pod_label_app_kubernetes_io_component",
        "__meta_kubernetes_pod_label_k8s_component",
        "__meta_kubernetes_pod_label_component",
      ]
      regex = "^(?:;*)?([^;]+).*$"
      replacement = "$1"
      target_label = "component"
    }

    // set a source label
    rule {
      action = "replace"
      replacement = "kubernetes"
      target_label = "source"
    }
  }

  prometheus.scrape "cert_manager" {
    targets = discovery.relabel.cert_manager.output
    job_name = "integrations/cert-manager"
    scrape_interval = "60s"
    scrape_timeout = "10s"
    scrape_protocols = ["OpenMetricsText1.0.0","OpenMetricsText0.0.1","PrometheusText0.0.4"]
    scrape_classic_histograms = false
    scrape_native_histograms = false
    clustering {
      enabled = true
    }
    forward_to = argument.metrics_destinations.value
  }
}
cert_manager_integration "integration" {
  metrics_destinations = [
    prometheus.remote_write.prometheus.receiver,
  ]
}
declare "mysql_integration" {
  argument "metrics_destinations" {
    comment = "Must be a list of metric destinations where collected metrics should be forwarded to"
  }
  argument "logs_destinations" {
    comment = "Must be a list of log destinations where collected logs should be forwarded to"
  }

  remote.kubernetes.secret "mysql_cluster" {
    name      = "mysql-cluster-k8smon-integrations"
    namespace = "default"
  }

  prometheus.exporter.mysql "mysql_cluster" {
    data_source_name = string.format("%s:%s@(%s:%d)/",
      convert.nonsensitive(remote.kubernetes.secret.mysql_cluster.data["username"]),
      convert.nonsensitive(remote.kubernetes.secret.mysql_cluster.data["password"]),
      "mysql-cluster-router.mysql-cluster",
      3306,
    )
    enable_collectors = ["perf_schema.replication_group_members"]
  }
  prometheus.scrape "mysql_cluster" {
    targets = prometheus.exporter.mysql.mysql_cluster.targets
    clustering {
      enabled = true
    }

    scrape_interval = "60s"
    scrape_timeout = "10s"
    scrape_protocols = ["OpenMetricsText1.0.0","OpenMetricsText0.0.1","PrometheusText0.0.4"]
    scrape_classic_histograms = false
    scrape_native_histograms = false
    forward_to = [prometheus.relabel.mysql_cluster.receiver]
  }

  prometheus.relabel "mysql_cluster" {
    max_cache_size = 100000
    rule {
      target_label = "instance"
      replacement = "mysql-cluster"
    }
    rule {
      target_label = "job"
      replacement = "integration/mysql"
    }
    rule {
      source_labels = ["__name__"]
      regex = "mysql_exporter_collector_duration_seconds|mysql_exporter_collector_success"
      action = "drop"
    }
    forward_to = argument.metrics_destinations.value
  }
}
mysql_integration "integration" {
  metrics_destinations = [
    prometheus.remote_write.prometheus.receiver,
  ]
  logs_destinations = [
    loki.write.loki.receiver,
  ]
}
// Self Reporting
prometheus.exporter.unix "kubernetes_monitoring_telemetry" {
  set_collectors = ["textfile"]
  textfile {
    directory = "/etc/alloy"
  }
}

discovery.relabel "kubernetes_monitoring_telemetry" {
  targets = prometheus.exporter.unix.kubernetes_monitoring_telemetry.targets
  rule {
    target_label = "instance"
    action = "replace"
    replacement = "k8smon"
  }
  rule {
    target_label = "job"
    action = "replace"
    replacement = "integrations/kubernetes/kubernetes_monitoring_telemetry"
  }
}

prometheus.scrape "kubernetes_monitoring_telemetry" {
  job_name   = "integrations/kubernetes/kubernetes_monitoring_telemetry"
  targets    = discovery.relabel.kubernetes_monitoring_telemetry.output
  scrape_interval = "60s"
  clustering {
    enabled = true
  }
  forward_to = [prometheus.relabel.kubernetes_monitoring_telemetry.receiver]
}

prometheus.relabel "kubernetes_monitoring_telemetry" {
  rule {
    source_labels = ["__name__"]
    regex = "grafana_kubernetes_monitoring_.*"
    action = "keep"
  }
  forward_to = [
    prometheus.remote_write.prometheus.receiver,
  ]
}




// Destination: prometheus (prometheus)
otelcol.exporter.prometheus "prometheus" {
  add_metric_suffixes = true
  resource_to_telemetry_conversion = false
  forward_to = [prometheus.remote_write.prometheus.receiver]
}

prometheus.remote_write "prometheus" {
  endpoint {
    url = "http://prometheus.prometheus.svc:9090/api/v1/write"
    headers = {
    }
    tls_config {
      insecure_skip_verify = false
    }
    send_native_histograms = false

    queue_config {
      capacity = 10000
      min_shards = 1
      max_shards = 50
      max_samples_per_send = 2000
      batch_send_deadline = "5s"
      min_backoff = "30ms"
      max_backoff = "5s"
      retry_on_http_429 = true
      sample_age_limit = "0s"
    }

    write_relabel_config {
      source_labels = ["cluster"]
      regex = ""
      replacement = "multiple-integrations-example"
      target_label = "cluster"
    }
    write_relabel_config {
      source_labels = ["k8s_cluster_name"]
      regex = ""
      replacement = "multiple-integrations-example"
      target_label = "k8s_cluster_name"
    }
  }

  wal {
    truncate_frequency = "2h"
    min_keepalive_time = "5m"
    max_keepalive_time = "8h"
  }
}
// Destination: loki (loki)
otelcol.exporter.loki "loki" {
  forward_to = [loki.write.loki.receiver]
}

loki.write "loki" {
  endpoint {
    url = "http://loki.loki.svc:3100/api/push"
    retry_on_http_429 = true
    tls_config {
      insecure_skip_verify = false
    }
    min_backoff_period = "500ms"
    max_backoff_period = "5m"
    max_backoff_retries = "10"
  }
  external_labels = {
    "cluster" = "multiple-integrations-example",
    "k8s_cluster_name" = "multiple-integrations-example",
  }
}

