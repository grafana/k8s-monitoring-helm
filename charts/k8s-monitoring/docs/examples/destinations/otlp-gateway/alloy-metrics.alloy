// Destination: otlp-gateway (otlp)
otelcol.receiver.prometheus "otlp_gateway" {
  output {
    metrics = [otelcol.processor.attributes.otlp_gateway.input]
  }
}
otelcol.receiver.loki "otlp_gateway" {
  output {
    logs = [otelcol.processor.attributes.otlp_gateway.input]
  }
}
otelcol.auth.basic "otlp_gateway" {
  username = nonsensitive(remote.kubernetes.secret.otlp_gateway.data["username"])
  password = remote.kubernetes.secret.otlp_gateway.data["password"]
}

otelcol.processor.attributes "otlp_gateway" {
  action {
    key = "cluster"
    action = "upsert"
    value = "otlp-gateway-test"
  }
  action {
    key = "k8s.cluster.name"
    action = "upsert"
    value = "otlp-gateway-test"
  }
  output {
    metrics = [otelcol.processor.transform.otlp_gateway.input]
    logs = [otelcol.processor.transform.otlp_gateway.input]
    traces = [otelcol.processor.transform.otlp_gateway.input]
  }
}

otelcol.processor.transform "otlp_gateway" {
  error_mode = "ignore"

  output {
    metrics = [otelcol.processor.batch.otlp_gateway.input]
    logs = [otelcol.processor.batch.otlp_gateway.input]
    traces = [otelcol.processor.batch.otlp_gateway.input]
  }
}

otelcol.processor.batch "otlp_gateway" {
  timeout = "2s"
  send_batch_size = 8192
  send_batch_max_size = 0

  output {
    metrics = [otelcol.exporter.otlphttp.otlp_gateway.input]
    logs = [otelcol.exporter.otlphttp.otlp_gateway.input]
    traces = [otelcol.exporter.otlphttp.otlp_gateway.input]
  }
}
otelcol.exporter.otlphttp "otlp_gateway" {
  client {
    endpoint = "https://otlp-gateway-my-region.grafana.net/otlp"
    auth = otelcol.auth.basic.otlp_gateway.handler
    tls {
      insecure = false
      insecure_skip_verify = false
    }
  }
}

remote.kubernetes.secret "otlp_gateway" {
  name      = "otlp-gateway-k8smon-k8s-monitoring"
  namespace = "default"
}

// Feature: Cluster Metrics
declare "cluster_metrics" {
  argument "metrics_destinations" {
    comment = "Must be a list of metric destinations where collected metrics should be forwarded to"
  }
  
  remote.kubernetes.configmap "kubernetes" {
    name = "k8smon-alloy-module-kubernetes"
    namespace = "default"
  }
  
  import.string "kubernetes" {
    content = remote.kubernetes.configmap.kubernetes.data["core_metrics.alloy"]
  }  
  
  kubernetes.kubelet "scrape" {
    clustering = true
    keep_metrics = "up|go_goroutines|kubelet_certificate_manager_client_expiration_renew_errors|kubelet_certificate_manager_client_ttl_seconds|kubelet_certificate_manager_server_ttl_seconds|kubelet_cgroup_manager_duration_seconds_bucket|kubelet_cgroup_manager_duration_seconds_count|kubelet_node_config_error|kubelet_node_name|kubelet_pleg_relist_duration_seconds_bucket|kubelet_pleg_relist_duration_seconds_count|kubelet_pleg_relist_interval_seconds_bucket|kubelet_pod_start_duration_seconds_bucket|kubelet_pod_start_duration_seconds_count|kubelet_pod_worker_duration_seconds_bucket|kubelet_pod_worker_duration_seconds_count|kubelet_running_container_count|kubelet_running_containers|kubelet_running_pod_count|kubelet_running_pods|kubelet_runtime_operations_errors_total|kubelet_runtime_operations_total|kubelet_server_expiration_renew_errors|kubelet_volume_stats_available_bytes|kubelet_volume_stats_capacity_bytes|kubelet_volume_stats_inodes|kubelet_volume_stats_inodes_free|kubelet_volume_stats_inodes_used|kubelet_volume_stats_used_bytes|kubernetes_build_info|namespace_workload_pod|process_cpu_seconds_total|process_resident_memory_bytes|rest_client_requests_total|storage_operation_duration_seconds_count|storage_operation_errors_total|volume_manager_total_volumes"
    scrape_interval = "60s"
    max_cache_size = 100000
    forward_to = argument.metrics_destinations.value
  }  
  
  kubernetes.resources "scrape" {
    clustering = true
    job_label = "integrations/kubernetes/resources"
    keep_metrics = "up|node_cpu_usage_seconds_total|node_memory_working_set_bytes"
    scrape_interval = "60s"
    max_cache_size = 100000
    forward_to = argument.metrics_destinations.value
  }  
  
  kubernetes.cadvisor "scrape" {
    clustering = true
    keep_metrics = "up|container_cpu_cfs_periods_total|container_cpu_cfs_throttled_periods_total|container_cpu_usage_seconds_total|container_fs_reads_bytes_total|container_fs_reads_total|container_fs_writes_bytes_total|container_fs_writes_total|container_memory_cache|container_memory_rss|container_memory_swap|container_memory_working_set_bytes|container_network_receive_bytes_total|container_network_receive_packets_dropped_total|container_network_receive_packets_total|container_network_transmit_bytes_total|container_network_transmit_packets_dropped_total|container_network_transmit_packets_total|machine_memory_bytes"
    scrape_interval = "60s"
    max_cache_size = 100000
    forward_to = [prometheus.relabel.cadvisor.receiver]
  }
  
  prometheus.relabel "cadvisor" {
    max_cache_size = 100000
    // Drop empty container labels, addressing https://github.com/google/cadvisor/issues/2688
    rule {
      source_labels = ["__name__","container"]
      separator = "@"
      regex = "(container_cpu_.*|container_fs_.*|container_memory_.*)@"
      action = "drop"
    }
    // Drop empty image labels, addressing https://github.com/google/cadvisor/issues/2688
    rule {
      source_labels = ["__name__","image"]
      separator = "@"
      regex = "(container_cpu_.*|container_fs_.*|container_memory_.*|container_network_.*)@"
      action = "drop"
    }
    // Normalizing unimportant labels (not deleting to continue satisfying <label>!="" checks)
    rule {
      source_labels = ["__name__", "boot_id"]
      separator = "@"
      regex = "machine_memory_bytes@.*"
      target_label = "boot_id"
      replacement = "NA"
    }
    rule {
      source_labels = ["__name__", "system_uuid"]
      separator = "@"
      regex = "machine_memory_bytes@.*"
      target_label = "system_uuid"
      replacement = "NA"
    }
    // Filter out non-physical devices/interfaces
    rule {
      source_labels = ["__name__", "device"]
      separator = "@"
      regex = "container_fs_.*@(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dasd.+)"
      target_label = "__keepme"
      replacement = "1"
    }
    rule {
      source_labels = ["__name__", "__keepme"]
      separator = "@"
      regex = "container_fs_.*@"
      action = "drop"
    }
    rule {
      source_labels = ["__name__"]
      regex = "container_fs_.*"
      target_label = "__keepme"
      replacement = ""
    }
    rule {
      source_labels = ["__name__", "interface"]
      separator = "@"
      regex = "container_network_.*@(en[ospx][0-9].*|wlan[0-9].*|eth[0-9].*)"
      target_label = "__keepme"
      replacement = "1"
    }
    rule {
      source_labels = ["__name__", "__keepme"]
      separator = "@"
      regex = "container_network_.*@"
      action = "drop"
    }
    rule {
      source_labels = ["__name__"]
      regex = "container_network_.*"
      target_label = "__keepme"
      replacement = ""
    }
    forward_to = argument.metrics_destinations.value
  }            
  
  remote.kubernetes.configmap "kube_state_metrics" {
    name = "k8smon-alloy-module-kubernetes"
    namespace = "default"
  }
  
  import.string "kube_state_metrics" {
    content = remote.kubernetes.configmap.kube_state_metrics.data["kube-state-metrics_metrics.alloy"]
  }
  
  kube_state_metrics.kubernetes "targets" {
    label_selectors = [
      "app.kubernetes.io/name=kube-state-metrics",
      "release=k8smon",
    ]
  }
  
  kube_state_metrics.scrape "metrics" {
    targets = kube_state_metrics.kubernetes.targets.output
    clustering = true
    keep_metrics = "up|kube_daemonset.*|kube_deployment_metadata_generation|kube_deployment_spec_replicas|kube_deployment_status_condition|kube_deployment_status_observed_generation|kube_deployment_status_replicas_available|kube_deployment_status_replicas_updated|kube_horizontalpodautoscaler_spec_max_replicas|kube_horizontalpodautoscaler_spec_min_replicas|kube_horizontalpodautoscaler_status_current_replicas|kube_horizontalpodautoscaler_status_desired_replicas|kube_job.*|kube_namespace_status_phase|kube_node.*|kube_persistentvolume_status_phase|kube_persistentvolumeclaim_access_mode|kube_persistentvolumeclaim_info|kube_persistentvolumeclaim_labels|kube_persistentvolumeclaim_resource_requests_storage_bytes|kube_persistentvolumeclaim_status_phase|kube_pod_container_info|kube_pod_container_resource_limits|kube_pod_container_resource_requests|kube_pod_container_status_last_terminated_reason|kube_pod_container_status_restarts_total|kube_pod_container_status_waiting_reason|kube_pod_info|kube_pod_owner|kube_pod_spec_volumes_persistentvolumeclaims_info|kube_pod_start_time|kube_pod_status_phase|kube_pod_status_reason|kube_replicaset.*|kube_resourcequota|kube_statefulset.*"
    scrape_interval = "60s"
    max_cache_size = 100000
    forward_to = argument.metrics_destinations.value
  }  
  
  remote.kubernetes.configmap "node_exporter" {
    name = "k8smon-alloy-module-system"
    namespace = "default"
  }
  
  import.string "node_exporter" {
    content = remote.kubernetes.configmap.node_exporter.data["node-exporter_metrics.alloy"]
  }
  
  node_exporter.kubernetes "targets" {
    label_selectors = [
      "app.kubernetes.io/name=node-exporter",
      "release=k8smon",
    ]
  }
  
  discovery.relabel "node_exporter" {
    targets = node_exporter.kubernetes.targets.output
    rule {
      source_labels = ["__meta_kubernetes_pod_node_name"]
      action = "replace"
      target_label = "instance"
    }
  }
  
  node_exporter.scrape "metrics" {
    targets = discovery.relabel.node_exporter.output
    job_label = "integrations/node_exporter"
    clustering = true
    keep_metrics = "up|node_cpu.*|node_exporter_build_info|node_filesystem.*|node_memory.*|node_network_receive_bytes_total|node_network_receive_drop_total|node_network_transmit_bytes_total|node_network_transmit_drop_total|process_cpu_seconds_total|process_resident_memory_bytes"
    scrape_interval = "60s"
    max_cache_size = 100000
    forward_to = argument.metrics_destinations.value
  }  
  
  discovery.kubernetes "windows_exporter_pods" {
    role = "pod"
    namespaces {
      names = ["default"]
    }
    selectors {
      role = "pod"
      label = "app.kubernetes.io/name=windows-exporter,release=k8smon"
    }
  }
  
  discovery.relabel "windows_exporter" {
    targets = discovery.kubernetes.windows_exporter_pods.targets
    rule {
      source_labels = ["__meta_kubernetes_pod_node_name"]
      action = "replace"
      target_label = "instance"
    }
  }
  
  prometheus.scrape "windows_exporter" {
    job_name   = "integrations/windows-exporter"
    targets  = discovery.relabel.windows_exporter.output
    scrape_interval = "60s"
    clustering {
      enabled = true
    }
    forward_to = [prometheus.relabel.windows_exporter.receiver]
  }
  
  prometheus.relabel "windows_exporter" {
    max_cache_size = 100000
    rule {
      source_labels = ["__name__"]
      regex = "up|windows_.*|node_cpu_seconds_total|node_filesystem_size_bytes|node_filesystem_avail_bytes|container_cpu_usage_seconds_total"
      action = "keep"
    }
    forward_to = argument.metrics_destinations.value
  }    
}
cluster_metrics "feature" {
  metrics_destinations = [
    otelcol.receiver.prometheus.otlp_gateway.receiver,
  ]
}

// Self Reporting
prometheus.exporter.unix "kubernetes_monitoring_telemetry" {
  set_collectors = ["textfile"]
  textfile {
    directory = "/etc/alloy"
  }
}

discovery.relabel "kubernetes_monitoring_telemetry" {
  targets = prometheus.exporter.unix.kubernetes_monitoring_telemetry.targets
  rule {
    target_label = "instance"
    action = "replace"
    replacement = "k8smon"
  }
  rule {
    target_label = "job"
    action = "replace"
    replacement = "integrations/kubernetes/kubernetes_monitoring_telemetry"
  }
}

prometheus.scrape "kubernetes_monitoring_telemetry" {
  job_name   = "integrations/kubernetes/kubernetes_monitoring_telemetry"
  targets    = discovery.relabel.kubernetes_monitoring_telemetry.output
  scrape_interval = "1h"
  clustering {
    enabled = true
  }
  forward_to = [prometheus.relabel.kubernetes_monitoring_telemetry.receiver]
}

prometheus.relabel "kubernetes_monitoring_telemetry" {
  rule {
    source_labels = ["__name__"]
    regex = "grafana_kubernetes_monitoring_.*"
    action = "keep"
  }
  forward_to = [
    otelcol.receiver.prometheus.otlp_gateway.receiver,
  ]
}
