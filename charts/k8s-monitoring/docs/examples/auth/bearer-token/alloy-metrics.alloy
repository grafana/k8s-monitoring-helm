// Feature: Prometheus Operator Objects
declare "prometheus_operator_objects" {
  argument "metrics_destinations" {
    comment = "Must be a list of metric destinations where collected metrics should be forwarded to"
  }

  // Prometheus Operator PodMonitor objects
  prometheus.operator.podmonitors "pod_monitors" {
    clustering {
      enabled = true
    }
    scrape {
      default_scrape_interval = "60s"
    }
    forward_to = argument.metrics_destinations.value
  }

  // Prometheus Operator Probe objects
  prometheus.operator.probes "probes" {
    clustering {
      enabled = true
    }
    scrape {
      default_scrape_interval = "60s"
    }
    forward_to = argument.metrics_destinations.value
  }

  // Prometheus Operator ServiceMonitor objects
  prometheus.operator.servicemonitors "service_monitors" {
    clustering {
      enabled = true
    }
    scrape {
      default_scrape_interval = "60s"
    }
    forward_to = argument.metrics_destinations.value
  }
}
prometheus_operator_objects "feature" {
  metrics_destinations = [
    prometheus.remote_write.prometheus.receiver,
  ]
}
// Self Reporting
prometheus.exporter.unix "kubernetes_monitoring_telemetry" {
  set_collectors = ["textfile"]
  textfile {
    directory = "/etc/alloy"
  }
}

discovery.relabel "kubernetes_monitoring_telemetry" {
  targets = prometheus.exporter.unix.kubernetes_monitoring_telemetry.targets
  rule {
    target_label = "instance"
    action = "replace"
    replacement = "k8smon"
  }
  rule {
    target_label = "job"
    action = "replace"
    replacement = "integrations/kubernetes/kubernetes_monitoring_telemetry"
  }
}

prometheus.scrape "kubernetes_monitoring_telemetry" {
  job_name   = "integrations/kubernetes/kubernetes_monitoring_telemetry"
  targets    = discovery.relabel.kubernetes_monitoring_telemetry.output
  scrape_interval = "60s"
  clustering {
    enabled = true
  }
  forward_to = [prometheus.relabel.kubernetes_monitoring_telemetry.receiver]
}

prometheus.relabel "kubernetes_monitoring_telemetry" {
  rule {
    source_labels = ["__name__"]
    regex = "grafana_kubernetes_monitoring_.*"
    action = "keep"
  }
  forward_to = [
    prometheus.remote_write.prometheus.receiver,
  ]
}




// Destination: prometheus (prometheus)
otelcol.exporter.prometheus "prometheus" {
  add_metric_suffixes = true
  forward_to = [prometheus.remote_write.prometheus.receiver]
}

prometheus.remote_write "prometheus" {
  endpoint {
    url = "http://prometheus.prometheus.svc:9090/api/v1/write"
    headers = {
    }
    bearer_token = remote.kubernetes.secret.prometheus.data["bearerToken"]
    tls_config {
      insecure_skip_verify = false
    }
    send_native_histograms = false

    queue_config {
      capacity = 10000
      min_shards = 1
      max_shards = 50
      max_samples_per_send = 2000
      batch_send_deadline = "5s"
      min_backoff = "30ms"
      max_backoff = "5s"
      retry_on_http_429 = true
      sample_age_limit = "0s"
    }

    write_relabel_config {
      source_labels = ["cluster"]
      regex = ""
      replacement = "bearer-token-example-cluster"
      target_label = "cluster"
    }
    write_relabel_config {
      source_labels = ["k8s_cluster_name"]
      regex = ""
      replacement = "bearer-token-example-cluster"
      target_label = "k8s_cluster_name"
    }
  }

  wal {
    truncate_frequency = "2h"
    min_keepalive_time = "5m"
    max_keepalive_time = "8h"
  }
}

remote.kubernetes.secret "prometheus" {
  name      = "prometheus-k8smon-k8s-monitoring"
  namespace = "default"
}

// Destination: loki (loki)
otelcol.exporter.loki "loki" {
  forward_to = [loki.write.loki.receiver]
}

loki.write "loki" {
  endpoint {
    url = "http://loki.loki.svc:3100/loki/api/v1/push"
    bearer_token = env("LOKI_BEARER_TOKEN")
    tls_config {
      insecure_skip_verify = false
    }
    min_backoff_period = "500ms"
    max_backoff_period = "5m"
    max_backoff_retries = "10"
  }
  external_labels = {
    "cluster" = "bearer-token-example-cluster",
    "k8s_cluster_name" = "bearer-token-example-cluster",
  }
}
// Destination: tempo (otlp)
otelcol.auth.bearer "tempo" {
  token = remote.kubernetes.secret.tempo.data["tempoBearerToken"]
}

otelcol.processor.attributes "tempo" {
  output {
    metrics = [otelcol.processor.transform.tempo.input]
    logs = [otelcol.processor.transform.tempo.input]
    traces = [otelcol.processor.transform.tempo.input]
  }
}

otelcol.processor.transform "tempo" {
  error_mode = "ignore"
  metric_statements {
    context = "resource"
    statements = [
      `set(attributes["cluster"], "bearer-token-example-cluster")`,
      `set(attributes["k8s.cluster.name"], "bearer-token-example-cluster")`,
    ]
  }

  metric_statements {
    context = "datapoint"
    statements = [
      `set(attributes["cluster"], "bearer-token-example-cluster")`,
      `set(attributes["k8s.cluster.name"], "bearer-token-example-cluster")`,
    ]
  }
  log_statements {
    context = "resource"
    statements = [
      `set(attributes["cluster"], "bearer-token-example-cluster")`,
      `set(attributes["k8s.cluster.name"], "bearer-token-example-cluster")`,
    ]
  }

  log_statements {
    context = "log"
    statements = [
      `delete_key(attributes, "loki.attribute.labels")`,
      `delete_key(attributes, "loki.resource.labels")`,
      `set(resource.attributes["service.name"], attributes["service_name"]) where resource.attributes["service.name"] == nil and attributes["service_name"] != nil`,
      `delete_key(attributes, "service_name") where attributes["service_name"] != nil`,
      `set(resource.attributes["service.namespace"], attributes["service_namespace"] ) where resource.attributes["service.namespace"] == nil and attributes["service_namespace"] != nil`,
      `delete_key(attributes, "service_namespace") where attributes["service_namespace"] != nil`,
      `set(resource.attributes["deployment.environment.name"], attributes["deployment_environment_name"] ) where resource.attributes["deployment.environment.name"] == nil and attributes["deployment_environment_name"] != nil`,
      `delete_key(attributes, "deployment_environment_name") where attributes["deployment_environment_name"] != nil`,
      `set(resource.attributes["deployment.environment"], attributes["deployment_environment"] ) where resource.attributes["deployment.environment"] == nil and attributes["deployment_environment"] != nil`,
      `delete_key(attributes, "deployment_environment") where attributes["deployment_environment"] != nil`,
    ]
  }

  trace_statements {
    context = "resource"
    statements = [
      `set(attributes["cluster"], "bearer-token-example-cluster")`,
      `set(attributes["k8s.cluster.name"], "bearer-token-example-cluster")`,
    ]
  }

  output {
    metrics = [otelcol.processor.batch.tempo.input]
    logs = [otelcol.processor.batch.tempo.input]
    traces = [otelcol.processor.batch.tempo.input]
  }
}

otelcol.processor.batch "tempo" {
  timeout = "2s"
  send_batch_size = 8192
  send_batch_max_size = 0

  output {
    metrics = [otelcol.exporter.otlp.tempo.input]
    logs = [otelcol.exporter.otlp.tempo.input]
    traces = [otelcol.exporter.otlp.tempo.input]
  }
}
otelcol.exporter.otlp "tempo" {
  client {
    endpoint = "http://tempo.tempo.svc:4317"
    auth = otelcol.auth.bearer.tempo.handler
    headers = {
      "X-Scope-OrgID" = convert.nonsensitive(remote.kubernetes.secret.tempo.data["tenantId"]),
    }
    tls {
      insecure = false
      insecure_skip_verify = false
      ca_pem = convert.nonsensitive(remote.kubernetes.secret.tempo.data["ca"])
      cert_pem = convert.nonsensitive(remote.kubernetes.secret.tempo.data["cert"])
      key_pem = remote.kubernetes.secret.tempo.data["key"]
    }
  }

  retry_on_failure {
    enabled = true
    initial_interval = "5s"
    max_interval = "30s"
    max_elapsed_time = "5m"
  }
}

remote.kubernetes.secret "tempo" {
  name      = "my-tempo-secret"
  namespace = "tempo"
}
