// Feature: Cluster Metrics
declare "cluster_metrics" {
  argument "metrics_destinations" {
    comment = "Must be a list of metric destinations where collected metrics should be forwarded to"
  }
  discovery.kubernetes "kube_state_metrics" {
    role = "endpoints"

    selectors {
      role = "endpoints"
      label = "release=k8smon,app.kubernetes.io/name=kube-state-metrics"
    }
    namespaces {
      names = ["default"]
    }
  }

  discovery.relabel "kube_state_metrics" {
    targets = discovery.kubernetes.kube_state_metrics.targets

    rule {
      action = "replace"
      replacement = "kubernetes"
      target_label = "source"
    }

  }

  prometheus.scrape "kube_state_metrics" {
    targets = discovery.relabel.kube_state_metrics.output
    job_name = "integrations/kubernetes/kube-state-metrics"
    scrape_interval = "60s"
    scrape_timeout = "10s"
    scrape_protocols = ["OpenMetricsText1.0.0","OpenMetricsText0.0.1","PrometheusText0.0.4"]
    scrape_classic_histograms = false
    scrape_native_histograms = false
    scheme = "http"
    bearer_token_file = ""
    tls_config {
      insecure_skip_verify = true
    }

    clustering {
      enabled = true
    }
    forward_to = [prometheus.relabel.kube_state_metrics.receiver]
  }

  prometheus.relabel "kube_state_metrics" {
    max_cache_size = 100000
    rule {
      source_labels = ["__name__"]
      regex = "up|scrape_samples_scraped|kube_configmap_info|kube_configmap_metadata_resource_version|kube_cronjob.*|kube_daemonset.*|kube_deployment_metadata_generation|kube_deployment_spec_replicas|kube_deployment_status_condition|kube_deployment_status_observed_generation|kube_deployment_status_replicas_available|kube_deployment_status_replicas_updated|kube_horizontalpodautoscaler_spec_max_replicas|kube_horizontalpodautoscaler_spec_min_replicas|kube_horizontalpodautoscaler_status_current_replicas|kube_horizontalpodautoscaler_status_desired_replicas|kube_job.*|kube_namespace_status_phase|kube_node.*|kube_persistentvolume_status_phase|kube_persistentvolumeclaim_access_mode|kube_persistentvolumeclaim_info|kube_persistentvolumeclaim_labels|kube_persistentvolumeclaim_resource_requests_storage_bytes|kube_persistentvolumeclaim_status_phase|kube_pod_completion_time|kube_pod_container_info|kube_pod_container_resource_limits|kube_pod_container_resource_requests|kube_pod_container_status_last_terminated_reason|kube_pod_container_status_last_terminated_timestamp|kube_pod_container_status_restarts_total|kube_pod_container_status_waiting_reason|kube_pod_info|kube_pod_owner|kube_pod_restart_policy|kube_pod_spec_volumes_persistentvolumeclaims_info|kube_pod_start_time|kube_pod_status_phase|kube_pod_status_reason|kube_pod_init_.*|kube_replicaset.*|kube_resourcequota|kube_secret_metadata_resource_version|kube_statefulset.*"
      action = "keep"
    }
    forward_to = argument.metrics_destinations.value
  }
}
cluster_metrics "feature" {
  metrics_destinations = [
    prometheus.remote_write.metric_store.receiver,
  ]
}
// Feature: Host Metrics
declare "host_metrics" {
  argument "metrics_destinations" {
    comment = "Must be a list of metric destinations where collected metrics should be forwarded to"
  }

  // Linux hosts via Node Exporter
  discovery.kubernetes "node_exporter" {
    role = "pod"

    selectors {
      role = "pod"
      label = "release=k8smon,app.kubernetes.io/name=node-exporter"
    }
    namespaces {
      names = ["default"]
    }
  }

  discovery.relabel "node_exporter" {
    targets = discovery.kubernetes.node_exporter.targets

    // keep only the specified metrics port name, and pods that are Running and ready
    rule {
      source_labels = [
        "__meta_kubernetes_pod_container_init",
        "__meta_kubernetes_pod_phase",
        "__meta_kubernetes_pod_ready",
      ]
      separator = "@"
      regex = "false@Running@true"
      action = "keep"
    }

    // Set the instance label to the node name
    rule {
      source_labels = ["__meta_kubernetes_pod_node_name"]
      action = "replace"
      target_label = "instance"
    }

    // set the namespace label
    rule {
      source_labels = ["__meta_kubernetes_namespace"]
      target_label  = "namespace"
    }

    // set the pod label
    rule {
      source_labels = ["__meta_kubernetes_pod_name"]
      target_label  = "pod"
    }

    // set the container label
    rule {
      source_labels = ["__meta_kubernetes_pod_container_name"]
      target_label  = "container"
    }

    // set a workload label
    rule {
      source_labels = [
        "__meta_kubernetes_pod_controller_kind",
        "__meta_kubernetes_pod_controller_name",
      ]
      separator = "/"
      target_label  = "workload"
    }
    // remove the hash from the ReplicaSet
    rule {
      source_labels = ["workload"]
      regex = "(ReplicaSet/.+)-.+"
      target_label  = "workload"
    }

    // set the app name if specified as metadata labels "app:" or "app.kubernetes.io/name:" or "k8s-app:"
    rule {
      action = "replace"
      source_labels = [
        "__meta_kubernetes_pod_label_app_kubernetes_io_name",
        "__meta_kubernetes_pod_label_k8s_app",
        "__meta_kubernetes_pod_label_app",
      ]
      separator = ";"
      regex = "^(?:;*)?([^;]+).*$"
      replacement = "$1"
      target_label = "app"
    }

    // set the component if specified as metadata labels "component:" or "app.kubernetes.io/component:" or "k8s-component:"
    rule {
      action = "replace"
      source_labels = [
        "__meta_kubernetes_pod_label_app_kubernetes_io_component",
        "__meta_kubernetes_pod_label_k8s_component",
        "__meta_kubernetes_pod_label_component",
      ]
      regex = "^(?:;*)?([^;]+).*$"
      replacement = "$1"
      target_label = "component"
    }

    // set a source label
    rule {
      action = "replace"
      replacement = "kubernetes"
      target_label = "source"
    }
  }

  prometheus.scrape "node_exporter" {
    targets = discovery.relabel.node_exporter.output
    job_name = "integrations/node_exporter"
    scrape_interval = "60s"
    scrape_timeout = "10s"
    scrape_protocols = ["OpenMetricsText1.0.0","OpenMetricsText0.0.1","PrometheusText0.0.4"]
    scrape_classic_histograms = false
    scrape_native_histograms = false
    scheme = "http"
    tls_config {
      insecure_skip_verify = true
    }

    clustering {
      enabled = true
    }
    forward_to = [prometheus.relabel.node_exporter.receiver]
  }

  prometheus.relabel "node_exporter" {
    max_cache_size = 100000
    rule {
      source_labels = ["__name__"]
      regex = "up|scrape_samples_scraped|node_cpu.*|node_exporter_build_info|node_filesystem.*|node_memory.*|node_network_receive_bytes_total|node_network_receive_drop_total|node_network_transmit_bytes_total|node_network_transmit_drop_total|process_cpu_seconds_total|process_resident_memory_bytes"
      action = "keep"
    }
    // Drop metrics for certain file systems
    rule {
      source_labels = ["__name__", "fstype"]
      separator = "@"
      regex = "node_filesystem.*@(ramfs|tmpfs)"
      action = "drop"
    }
    forward_to = argument.metrics_destinations.value
  }

  // Windows hosts via Windows Exporter
  discovery.kubernetes "windows_exporter_pods" {
    role = "pod"
    selectors {
      role = "pod"
      label = "release=k8smon,app.kubernetes.io/name=windows-exporter"
    }
    namespaces {
      names = ["default"]
    }
  }

  discovery.relabel "windows_exporter" {
    targets = discovery.kubernetes.windows_exporter_pods.targets

    // keep only the specified metrics port name, and pods that are Running and ready
    rule {
      source_labels = [
        "__meta_kubernetes_pod_container_init",
        "__meta_kubernetes_pod_phase",
        "__meta_kubernetes_pod_ready",
      ]
      separator = "@"
      regex = "false@Running@true"
      action = "keep"
    }

    // Set the instance label to the node name
    rule {
      source_labels = ["__meta_kubernetes_pod_node_name"]
      target_label = "instance"
    }
  }

  prometheus.scrape "windows_exporter" {
    targets  = discovery.relabel.windows_exporter.output
    job_name   = "integrations/windows-exporter"
    scrape_interval = "60s"
    scrape_timeout = "10s"
    scrape_protocols = ["OpenMetricsText1.0.0","OpenMetricsText0.0.1","PrometheusText0.0.4"]
    scrape_classic_histograms = false
    scrape_native_histograms = false
    clustering {
      enabled = false
    }
    forward_to = [prometheus.relabel.windows_exporter.receiver]
  }

  prometheus.relabel "windows_exporter" {
    max_cache_size = 100000
    rule {
      source_labels = ["__name__"]
      regex = "up|scrape_samples_scraped|windows_.*|node_cpu_seconds_total|node_filesystem_size_bytes|node_filesystem_avail_bytes|container_cpu_usage_seconds_total"
      action = "keep"
    }
    forward_to = argument.metrics_destinations.value
  }
}
host_metrics "feature" {
  metrics_destinations = [
    prometheus.remote_write.metric_store.receiver,
  ]
}




// Destination: metric-store (prometheus)
otelcol.exporter.prometheus "metric_store" {
  add_metric_suffixes = true
  resource_to_telemetry_conversion = false
  forward_to = [prometheus.remote_write.metric_store.receiver]
}

prometheus.remote_write "metric_store" {
  endpoint {
    url = "http://prometheus-server.prometheus.svc:9090/api/v1/write"
    headers = {
    }
    tls_config {
      insecure_skip_verify = false
    }
    send_native_histograms = false

    queue_config {
      capacity = 10000
      min_shards = 1
      max_shards = 50
      max_samples_per_send = 2000
      batch_send_deadline = "5s"
      min_backoff = "30ms"
      max_backoff = "5s"
      retry_on_http_429 = true
      sample_age_limit = "0s"
    }

    write_relabel_config {
      source_labels = ["cluster"]
      regex = ""
      replacement = "no-cluster-roles"
      target_label = "cluster"
    }
    write_relabel_config {
      source_labels = ["k8s_cluster_name"]
      regex = ""
      replacement = "no-cluster-roles"
      target_label = "k8s_cluster_name"
    }
  }

  wal {
    truncate_frequency = "2h"
    min_keepalive_time = "5m"
    max_keepalive_time = "8h"
  }
}

