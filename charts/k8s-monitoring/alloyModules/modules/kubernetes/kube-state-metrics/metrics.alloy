/*
Module: job-kube-state-metrics
Description: Scrapes Kube-State-Metrics, this is a separate scrape job, if you are also using annotation based scraping, you will want to explicitly
             disable kube-state-metrics from being scraped by this module and annotations by setting the following annotation on the kube-state-metrics
             metrics.agent.grafana.com/scrape: "false"

Note: Every argument except for "forward_to" is optional, and does have a defined default value.  However, the values for these
      arguments are not defined using the default = " ... " argument syntax, but rather using the coalesce(argument.value, " ... ").
      This is because if the argument passed in from another consuming module is set to null, the default = " ... " syntax will
      does not override the value passed in, where coalesce() will return the first non-null value.
*/
declare "kubernetes" {
  // arguments for kubernetes discovery
  argument "namespaces" {
    comment = "The namespaces to look for targets in (default: [] is all namespaces)"
    optional = true
  }

  argument "field_selectors" {
    // Docs: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
    comment = "The label selectors to use to find matching targets (default: [])"
    optional = true
  }

  argument "label_selectors" {
    // Docs: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
    comment = "The label selectors to use to find matching targets (default: [\"app.kubernetes.io/name=kube-state-metrics\"])"
    optional = true
  }

  argument "port_name" {
    comment = "The of the port to scrape metrics from (default: http)"
    optional = true
  }

  // kube state metrics service discovery for all of the pods
  discovery.kubernetes "ksm" {
    role = "service"

    selectors {
      role = "service"
      field = join(coalesce(argument.field_selectors.value, []), ",")
      label = join(coalesce(argument.label_selectors.value, ["app.kubernetes.io/name=kube-state-metrics"]), ",")
    }

    namespaces {
      names = coalesce(argument.namespaces.value, [])
    }
  }

  // kube-state-metrics relabelings (pre-scrape)
  discovery.relabel "ksm" {
    targets = discovery.kubernetes.ksm.targets

    // only keep targets with a matching port name
    rule {
      source_labels = ["__meta_kubernetes_service_port_name"]
      regex = coalesce(argument.port_name.value, "http")
      action = "keep"
    }

    // set a source label
    rule {
      action = "replace"
      replacement = "kubernetes"
      target_label = "source"
    }
  }

  export "output" {
    value = discovery.relabel.ksm.output
  }
}

declare "scrape" {
  argument "targets" {
    comment = "Must be a list() of targets"
  }

  argument "forward_to" {
    comment = "Must be a list(MetricsReceiver) where collected logs should be forwarded to"
  }

  argument "job_label" {
    comment = "The job label to add for all kube-kube_state_metrics metrics (default: integrations/kubernetes/kube-state-metrics)"
    optional = true
  }

  argument "keep_metrics" {
    comment = "A regular expression of metrics to keep (default: see below)"
    optional = true
  }

  argument "drop_metrics" {
    comment = "A regular expression of metrics to drop (default: see below)"
    optional = true
  }

  argument "scrape_interval" {
    comment = "How often to scrape metrics from the targets (default: 60s)"
    optional = true
  }

  argument "scrape_timeout" {
    comment = "How long before a scrape times out (default: 10s)"
    optional = true
  }

  argument "max_cache_size" {
    comment = "The maximum number of elements to hold in the relabeling cache (default: 100000).  This should be at least 2x-5x your largest scrape target or samples appended rate."
    optional = true
  }

  argument "clustering" {
    // Docs: https://grafana.com/docs/agent/latest/flow/concepts/clustering/
    comment = "Whether or not clustering should be enabled (default: false)"
    optional = true
  }

  // kube-state-metrics scrape job
  prometheus.scrape "kube_state_metrics" {
    job_name = coalesce(argument.job_label.value, "integrations/kubernetes/kube-state-metrics")
    forward_to = [prometheus.relabel.kube_state_metrics.receiver]
    targets = argument.targets.value
    scrape_interval = coalesce(argument.scrape_interval.value, "60s")
    scrape_timeout = coalesce(argument.scrape_timeout.value, "10s")

    clustering {
      enabled = coalesce(argument.clustering.value, false)
    }
  }

  // kube_state_metrics metric relabelings (post-scrape)
  prometheus.relabel "kube_state_metrics" {
    forward_to = argument.forward_to.value
    max_cache_size = coalesce(argument.max_cache_size.value, 100000)

    // drop metrics that match the drop_metrics regex
    rule {
      source_labels = ["__name__"]
      regex = coalesce(argument.drop_metrics.value, "(^(go|process)_.+$)")
      action = "drop"
    }

    // keep only metrics that match the keep_metrics regex
    rule {
      source_labels = ["__name__"]
      regex = coalesce(argument.keep_metrics.value, "(up|kube_(daemonset.*|deployment_(metadata_generation|spec_replicas|status_(observed_generation|replicas_(available|updated)))|horizontalpodautoscaler_(spec_(max|min)_replicas|status_(current|desired)_replicas)|job.*|namespace_status_phase|node.*|persistentvolumeclaim_resource_requests_storage_bytes|pod_(container_(info|resource_(limits|requests)|status_(last_terminated_reason|restarts_total|waiting_reason))|info|owner|start_time|status_(phase|reason))|replicaset.*|resourcequota|statefulset.*))")
      action = "keep"
    }
  }
}
