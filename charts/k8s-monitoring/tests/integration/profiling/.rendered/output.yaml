---
# Source: k8s-monitoring/charts/alloy-operator/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: k8smon-alloy-operator
  namespace: default
  labels:
    helm.sh/chart: alloy-operator-0.3.8
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.2.1"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
---
# Source: k8s-monitoring/templates/alloy-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: k8smon-alloy-profiles
  namespace: default
data:
  config.alloy: |
    // Feature: Profiling
    declare "profiling" {
      argument "profiles_destinations" {
        comment = "Must be a list of profile destinations where collected profiles should be forwarded to"
      }
      // Profiles: eBPF
      discovery.kubernetes "ebpf_pods" {
        role = "pod"
        selectors {
          role = "pod"
          field = "spec.nodeName=" + sys.env("HOSTNAME")
        }
      }
    
      discovery.relabel "ebpf_pods" {
        targets = discovery.kubernetes.ebpf_pods.targets
        rule {
          source_labels = ["__meta_kubernetes_pod_phase"]
          regex = "Succeeded|Failed|Completed"
          action = "drop"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_ebpf_enabled"]
          regex         = "true"
          action        = "keep"
        }
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          target_label = "namespace"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_name"]
          target_label = "pod"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_node_name"]
          target_label = "node"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_container_name"]
          target_label = "container"
        }
        // provide arbitrary service_name label, otherwise it will be set to {__meta_kubernetes_namespace}/{__meta_kubernetes_pod_container_name}
        rule {
          source_labels = ["__meta_kubernetes_namespace", "__meta_kubernetes_pod_container_name"]
          separator = "@"
          regex = "(.*)@(.*)"
          replacement = "ebpf/${1}/${2}"
          target_label = "service_name"
        }
        rule {
          replacement = "alloy/pyroscope.ebpf"
          target_label = "source"
        }
      }
    
      pyroscope.ebpf "ebpf_pods" {
        targets = discovery.relabel.ebpf_pods.output
        demangle = "none"
        forward_to = argument.profiles_destinations.value
      }
      // Profiles: Java
      discovery.kubernetes "java_pods" {
        role = "pod"
        selectors {
          role = "pod"
          field = "spec.nodeName=" + sys.env("HOSTNAME")
        }
      }
    
      discovery.relabel "potential_java_pods" {
        targets = discovery.kubernetes.java_pods.targets
        rule {
          source_labels = ["__meta_kubernetes_pod_phase"]
          regex         = "Succeeded|Failed|Completed"
          action        = "drop"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_java_enabled"]
          regex         = "true"
          action        = "keep"
        }
      }
    
      discovery.process "java_pods" {
        join = discovery.relabel.potential_java_pods.output
      }
    
      discovery.relabel "java_pods" {
        targets = discovery.process.java_pods.targets
        rule {
          source_labels = ["__meta_process_exe"]
          action = "keep"
          regex = ".*/java$"
        }
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          target_label = "namespace"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_name"]
          target_label = "pod"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_node_name"]
          target_label = "node"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_container_name"]
          target_label = "container"
        }
        rule {
          replacement = "alloy/pyroscope.java"
          target_label = "source"
        }
      }
    
      pyroscope.java "java_pods" {
        targets = discovery.relabel.java_pods.output
        profiling_config {
          interval = "60s"
          alloc = "512k"
          cpu = true
          sample_rate = 100
          lock = "10ms"
        }
        forward_to = argument.profiles_destinations.value
      }
      // Profiles: pprof
      discovery.kubernetes "pprof_pods" {
        role = "pod"
        selectors {
          role = "pod"
          field = "spec.nodeName=" + sys.env("HOSTNAME")
        }
      }
    
      discovery.relabel "pprof_pods" {
        targets = discovery.kubernetes.pprof_pods.targets
        rule {
          action        = "drop"
          source_labels = ["__meta_kubernetes_pod_phase"]
          regex         = "Pending|Succeeded|Failed|Completed"
        }
    
        rule {
          regex  = "__meta_kubernetes_pod_label_(.+)"
          action = "labelmap"
        }
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          target_label  = "namespace"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_name"]
          target_label  = "pod"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_container_name"]
          target_label  = "container"
        }
        rule {
          replacement = "alloy/pyroscope.pprof"
          target_label = "source"
        }
      }
    
      discovery.relabel "pprof_pods_block_default_name" {
        targets = discovery.relabel.pprof_pods.output
    
        // Keep only pods with the scrape annotation set
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_block_scrape"]
          regex         = "true"
          action        = "keep"
        }
    
        // Rules to choose the right container
        rule {
          source_labels = ["container"]
          target_label = "__tmp_container"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_block_container"]
          regex = "(.+)"
          target_label = "__tmp_container"
        }
        rule {
          source_labels = ["container"]
          action = "keepequal"
          target_label = "__tmp_container"
        }
        rule {
          action = "labeldrop"
          regex = "__tmp_container"
        }
    
        // Rules to choose the right port by name
        // The discovery generates a target for each declared container port of the pod.
        // If the portName annotation has value, keep only the target where the port name matches the one of the annotation.
        rule {
          source_labels = ["__meta_kubernetes_pod_container_port_name"]
          target_label = "__tmp_port"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port_name"]
          regex = "(.+)"
          target_label = "__tmp_port"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_container_port_name"]
          action = "keepequal"
          target_label = "__tmp_port"
        }
        rule {
          action = "labeldrop"
          regex = "__tmp_port"
        }
    
        // If the portNumber annotation has a value, override the target address to use it, regardless whether it is
        // one of the declared ports on that Pod.
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port", "__meta_kubernetes_pod_ip"]
          regex = "(\\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})"
          replacement = "[$2]:$1" // IPv6
          target_label = "__address__"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port", "__meta_kubernetes_pod_ip"]
          regex = "(\\d+);((([0-9]+?)(\\.|$)){4})" // IPv4, takes priority over IPv6 when both exists
          replacement = "$2:$1"
          target_label = "__address__"
        }
    
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_block_scheme"]
          regex         = "(https?)"
          target_label  = "__scheme__"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_block_path"]
          regex         = "(.+)"
          target_label  = "__profile_path__"
        }
      }
    
      pyroscope.scrape "pyroscope_scrape_block" {
        targets = discovery.relabel.pprof_pods_block_default_name.output
    
        bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"
        profiling_config {
          profile.block {
            enabled = true
          }
          profile.process_cpu {
            enabled = false
          }
          profile.fgprof {
            enabled = false
          }
          profile.godeltaprof_block {
            enabled = false
          }
          profile.godeltaprof_memory {
            enabled = false
          }
          profile.godeltaprof_mutex {
            enabled = false
          }
          profile.goroutine {
            enabled = false
          }
          profile.memory {
            enabled = false
          }
          profile.mutex {
            enabled = false
          }
        }
    
        scrape_interval = "15s"
        scrape_timeout = "18s"
    
        forward_to = argument.profiles_destinations.value
      }
      discovery.relabel "pprof_pods_cpu_default_name" {
        targets = discovery.relabel.pprof_pods.output
    
        // Keep only pods with the scrape annotation set
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_scrape"]
          regex         = "true"
          action        = "keep"
        }
    
        // Rules to choose the right container
        rule {
          source_labels = ["container"]
          target_label = "__tmp_container"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_container"]
          regex = "(.+)"
          target_label = "__tmp_container"
        }
        rule {
          source_labels = ["container"]
          action = "keepequal"
          target_label = "__tmp_container"
        }
        rule {
          action = "labeldrop"
          regex = "__tmp_container"
        }
    
        // Rules to choose the right port by name
        // The discovery generates a target for each declared container port of the pod.
        // If the portName annotation has value, keep only the target where the port name matches the one of the annotation.
        rule {
          source_labels = ["__meta_kubernetes_pod_container_port_name"]
          target_label = "__tmp_port"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port_name"]
          regex = "(.+)"
          target_label = "__tmp_port"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_container_port_name"]
          action = "keepequal"
          target_label = "__tmp_port"
        }
        rule {
          action = "labeldrop"
          regex = "__tmp_port"
        }
    
        // If the portNumber annotation has a value, override the target address to use it, regardless whether it is
        // one of the declared ports on that Pod.
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port", "__meta_kubernetes_pod_ip"]
          regex = "(\\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})"
          replacement = "[$2]:$1" // IPv6
          target_label = "__address__"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port", "__meta_kubernetes_pod_ip"]
          regex = "(\\d+);((([0-9]+?)(\\.|$)){4})" // IPv4, takes priority over IPv6 when both exists
          replacement = "$2:$1"
          target_label = "__address__"
        }
    
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_scheme"]
          regex         = "(https?)"
          target_label  = "__scheme__"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_path"]
          regex         = "(.+)"
          target_label  = "__profile_path__"
        }
      }
    
      pyroscope.scrape "pyroscope_scrape_cpu" {
        targets = discovery.relabel.pprof_pods_cpu_default_name.output
    
        bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"
        profiling_config {
          profile.block {
            enabled = false
          }
          profile.process_cpu {
            enabled = true
          }
          profile.fgprof {
            enabled = false
          }
          profile.godeltaprof_block {
            enabled = false
          }
          profile.godeltaprof_memory {
            enabled = false
          }
          profile.godeltaprof_mutex {
            enabled = false
          }
          profile.goroutine {
            enabled = false
          }
          profile.memory {
            enabled = false
          }
          profile.mutex {
            enabled = false
          }
        }
    
        scrape_interval = "15s"
        scrape_timeout = "18s"
    
        forward_to = argument.profiles_destinations.value
      }
      discovery.relabel "pprof_pods_fgprof_default_name" {
        targets = discovery.relabel.pprof_pods.output
    
        // Keep only pods with the scrape annotation set
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_scrape"]
          regex         = "true"
          action        = "keep"
        }
    
        // Rules to choose the right container
        rule {
          source_labels = ["container"]
          target_label = "__tmp_container"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_container"]
          regex = "(.+)"
          target_label = "__tmp_container"
        }
        rule {
          source_labels = ["container"]
          action = "keepequal"
          target_label = "__tmp_container"
        }
        rule {
          action = "labeldrop"
          regex = "__tmp_container"
        }
    
        // Rules to choose the right port by name
        // The discovery generates a target for each declared container port of the pod.
        // If the portName annotation has value, keep only the target where the port name matches the one of the annotation.
        rule {
          source_labels = ["__meta_kubernetes_pod_container_port_name"]
          target_label = "__tmp_port"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port_name"]
          regex = "(.+)"
          target_label = "__tmp_port"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_container_port_name"]
          action = "keepequal"
          target_label = "__tmp_port"
        }
        rule {
          action = "labeldrop"
          regex = "__tmp_port"
        }
    
        // If the portNumber annotation has a value, override the target address to use it, regardless whether it is
        // one of the declared ports on that Pod.
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port", "__meta_kubernetes_pod_ip"]
          regex = "(\\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})"
          replacement = "[$2]:$1" // IPv6
          target_label = "__address__"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port", "__meta_kubernetes_pod_ip"]
          regex = "(\\d+);((([0-9]+?)(\\.|$)){4})" // IPv4, takes priority over IPv6 when both exists
          replacement = "$2:$1"
          target_label = "__address__"
        }
    
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_scheme"]
          regex         = "(https?)"
          target_label  = "__scheme__"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_path"]
          regex         = "(.+)"
          target_label  = "__profile_path__"
        }
      }
    
      pyroscope.scrape "pyroscope_scrape_fgprof" {
        targets = discovery.relabel.pprof_pods_fgprof_default_name.output
    
        bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"
        profiling_config {
          profile.block {
            enabled = false
          }
          profile.process_cpu {
            enabled = false
          }
          profile.fgprof {
            enabled = true
          }
          profile.godeltaprof_block {
            enabled = false
          }
          profile.godeltaprof_memory {
            enabled = false
          }
          profile.godeltaprof_mutex {
            enabled = false
          }
          profile.goroutine {
            enabled = false
          }
          profile.memory {
            enabled = false
          }
          profile.mutex {
            enabled = false
          }
        }
    
        scrape_interval = "15s"
        scrape_timeout = "18s"
    
        forward_to = argument.profiles_destinations.value
      }
      discovery.relabel "pprof_pods_goroutine_default_name" {
        targets = discovery.relabel.pprof_pods.output
    
        // Keep only pods with the scrape annotation set
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_scrape"]
          regex         = "true"
          action        = "keep"
        }
    
        // Rules to choose the right container
        rule {
          source_labels = ["container"]
          target_label = "__tmp_container"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_container"]
          regex = "(.+)"
          target_label = "__tmp_container"
        }
        rule {
          source_labels = ["container"]
          action = "keepequal"
          target_label = "__tmp_container"
        }
        rule {
          action = "labeldrop"
          regex = "__tmp_container"
        }
    
        // Rules to choose the right port by name
        // The discovery generates a target for each declared container port of the pod.
        // If the portName annotation has value, keep only the target where the port name matches the one of the annotation.
        rule {
          source_labels = ["__meta_kubernetes_pod_container_port_name"]
          target_label = "__tmp_port"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port_name"]
          regex = "(.+)"
          target_label = "__tmp_port"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_container_port_name"]
          action = "keepequal"
          target_label = "__tmp_port"
        }
        rule {
          action = "labeldrop"
          regex = "__tmp_port"
        }
    
        // If the portNumber annotation has a value, override the target address to use it, regardless whether it is
        // one of the declared ports on that Pod.
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port", "__meta_kubernetes_pod_ip"]
          regex = "(\\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})"
          replacement = "[$2]:$1" // IPv6
          target_label = "__address__"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port", "__meta_kubernetes_pod_ip"]
          regex = "(\\d+);((([0-9]+?)(\\.|$)){4})" // IPv4, takes priority over IPv6 when both exists
          replacement = "$2:$1"
          target_label = "__address__"
        }
    
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_scheme"]
          regex         = "(https?)"
          target_label  = "__scheme__"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_path"]
          regex         = "(.+)"
          target_label  = "__profile_path__"
        }
      }
    
      pyroscope.scrape "pyroscope_scrape_goroutine" {
        targets = discovery.relabel.pprof_pods_goroutine_default_name.output
    
        bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"
        profiling_config {
          profile.block {
            enabled = false
          }
          profile.process_cpu {
            enabled = false
          }
          profile.fgprof {
            enabled = false
          }
          profile.godeltaprof_block {
            enabled = false
          }
          profile.godeltaprof_memory {
            enabled = false
          }
          profile.godeltaprof_mutex {
            enabled = false
          }
          profile.goroutine {
            enabled = true
          }
          profile.memory {
            enabled = false
          }
          profile.mutex {
            enabled = false
          }
        }
    
        scrape_interval = "15s"
        scrape_timeout = "18s"
    
        forward_to = argument.profiles_destinations.value
      }
      discovery.relabel "pprof_pods_memory_default_name" {
        targets = discovery.relabel.pprof_pods.output
    
        // Keep only pods with the scrape annotation set
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_scrape"]
          regex         = "true"
          action        = "keep"
        }
    
        // Rules to choose the right container
        rule {
          source_labels = ["container"]
          target_label = "__tmp_container"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_container"]
          regex = "(.+)"
          target_label = "__tmp_container"
        }
        rule {
          source_labels = ["container"]
          action = "keepequal"
          target_label = "__tmp_container"
        }
        rule {
          action = "labeldrop"
          regex = "__tmp_container"
        }
    
        // Rules to choose the right port by name
        // The discovery generates a target for each declared container port of the pod.
        // If the portName annotation has value, keep only the target where the port name matches the one of the annotation.
        rule {
          source_labels = ["__meta_kubernetes_pod_container_port_name"]
          target_label = "__tmp_port"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port_name"]
          regex = "(.+)"
          target_label = "__tmp_port"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_container_port_name"]
          action = "keepequal"
          target_label = "__tmp_port"
        }
        rule {
          action = "labeldrop"
          regex = "__tmp_port"
        }
    
        // If the portNumber annotation has a value, override the target address to use it, regardless whether it is
        // one of the declared ports on that Pod.
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port", "__meta_kubernetes_pod_ip"]
          regex = "(\\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})"
          replacement = "[$2]:$1" // IPv6
          target_label = "__address__"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port", "__meta_kubernetes_pod_ip"]
          regex = "(\\d+);((([0-9]+?)(\\.|$)){4})" // IPv4, takes priority over IPv6 when both exists
          replacement = "$2:$1"
          target_label = "__address__"
        }
    
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_scheme"]
          regex         = "(https?)"
          target_label  = "__scheme__"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_path"]
          regex         = "(.+)"
          target_label  = "__profile_path__"
        }
      }
    
      pyroscope.scrape "pyroscope_scrape_memory" {
        targets = discovery.relabel.pprof_pods_memory_default_name.output
    
        bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"
        profiling_config {
          profile.block {
            enabled = false
          }
          profile.process_cpu {
            enabled = false
          }
          profile.fgprof {
            enabled = false
          }
          profile.godeltaprof_block {
            enabled = false
          }
          profile.godeltaprof_memory {
            enabled = false
          }
          profile.godeltaprof_mutex {
            enabled = false
          }
          profile.goroutine {
            enabled = false
          }
          profile.memory {
            enabled = true
          }
          profile.mutex {
            enabled = false
          }
        }
    
        scrape_interval = "15s"
        scrape_timeout = "18s"
    
        forward_to = argument.profiles_destinations.value
      }
      discovery.relabel "pprof_pods_mutex_default_name" {
        targets = discovery.relabel.pprof_pods.output
    
        // Keep only pods with the scrape annotation set
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_scrape"]
          regex         = "true"
          action        = "keep"
        }
    
        // Rules to choose the right container
        rule {
          source_labels = ["container"]
          target_label = "__tmp_container"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_container"]
          regex = "(.+)"
          target_label = "__tmp_container"
        }
        rule {
          source_labels = ["container"]
          action = "keepequal"
          target_label = "__tmp_container"
        }
        rule {
          action = "labeldrop"
          regex = "__tmp_container"
        }
    
        // Rules to choose the right port by name
        // The discovery generates a target for each declared container port of the pod.
        // If the portName annotation has value, keep only the target where the port name matches the one of the annotation.
        rule {
          source_labels = ["__meta_kubernetes_pod_container_port_name"]
          target_label = "__tmp_port"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port_name"]
          regex = "(.+)"
          target_label = "__tmp_port"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_container_port_name"]
          action = "keepequal"
          target_label = "__tmp_port"
        }
        rule {
          action = "labeldrop"
          regex = "__tmp_port"
        }
    
        // If the portNumber annotation has a value, override the target address to use it, regardless whether it is
        // one of the declared ports on that Pod.
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port", "__meta_kubernetes_pod_ip"]
          regex = "(\\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})"
          replacement = "[$2]:$1" // IPv6
          target_label = "__address__"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port", "__meta_kubernetes_pod_ip"]
          regex = "(\\d+);((([0-9]+?)(\\.|$)){4})" // IPv4, takes priority over IPv6 when both exists
          replacement = "$2:$1"
          target_label = "__address__"
        }
    
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_scheme"]
          regex         = "(https?)"
          target_label  = "__scheme__"
        }
        rule {
          source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_path"]
          regex         = "(.+)"
          target_label  = "__profile_path__"
        }
      }
    
      pyroscope.scrape "pyroscope_scrape_mutex" {
        targets = discovery.relabel.pprof_pods_mutex_default_name.output
    
        bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"
        profiling_config {
          profile.block {
            enabled = false
          }
          profile.process_cpu {
            enabled = false
          }
          profile.fgprof {
            enabled = false
          }
          profile.godeltaprof_block {
            enabled = false
          }
          profile.godeltaprof_memory {
            enabled = false
          }
          profile.godeltaprof_mutex {
            enabled = false
          }
          profile.goroutine {
            enabled = false
          }
          profile.memory {
            enabled = false
          }
          profile.mutex {
            enabled = true
          }
        }
    
        scrape_interval = "15s"
        scrape_timeout = "18s"
    
        forward_to = argument.profiles_destinations.value
      }
    }
    profiling "feature" {
      profiles_destinations = [
        pyroscope.write.pyro.receiver,
      ]
    }
    
    
    
    
    // Destination: pyro (pyroscope)
    pyroscope.write "pyro" {
      endpoint {
        url = "http://pyroscope.pyroscope.svc:4040"
        headers = {
        }
        tls_config {
          insecure_skip_verify = false
        }
        min_backoff_period = "500ms"
        max_backoff_period = "5m"
        max_backoff_retries = "10"
      }
    
      external_labels = {
        "cluster" = "profiling-feature-test",
        "k8s_cluster_name" = "profiling-feature-test",
      }
    }
---
# Source: k8s-monitoring/charts/alloy-operator/templates/rbac/alloy-manager.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: k8smon-alloy-operator-alloy-manager
  labels:
    helm.sh/chart: alloy-operator-0.3.8
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.2.1"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - collectors.grafana.com
    resources:
      - alloys
      - alloys/status
      - alloys/finalizers
    verbs:
      - create
      - delete
      - get
      - list
      - patch
      - update
      - watch
---
# Source: k8s-monitoring/charts/alloy-operator/templates/rbac/alloy-objects.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: k8smon-alloy-operator
rules:
  # Rules which allow the management of ConfigMaps, ServiceAccounts, and Services.
  - apiGroups: [""]
    resources: ["configmaps", "secrets", "serviceaccounts", "services"]
    verbs: ["*"]
  # Rules which allow the management of DaemonSets, Deployments, and StatefulSets.
  - apiGroups: ["apps"]
    resources: ["daemonsets", "deployments", "statefulsets"]
    verbs: ["*"]
  # Rules which allow the management of Horizontal Pod Autoscalers.
  - apiGroups: ["autoscaling"]
    resources: ["horizontalpodautoscalers"]
    verbs: ["*"]
  # Rules which allow the management of Ingresses and NetworkPolicies.
  - apiGroups: ["networking.k8s.io"]
    resources: ["ingresses", "networkpolicies"]
    verbs: ["*"]
  # Rules which allow the management of PodDisruptionBudgets.
  - apiGroups: ["policy"]
    resources: ["poddisruptionbudgets"]
    verbs: ["*"]
  # Rules which allow the management of ClusterRoles and ClusterRoleBindings.
  - apiGroups: ["rbac.authorization.k8s.io"]
    resources: ["clusterroles", "clusterrolebindings"]
    verbs: ["*"]
---
# Source: k8s-monitoring/charts/alloy-operator/templates/rbac/alloy-manager.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: k8smon-alloy-operator-alloy-manager
  labels:
    helm.sh/chart: alloy-operator-0.3.8
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.2.1"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: k8smon-alloy-operator-alloy-manager
subjects:
  - kind: ServiceAccount
    name: k8smon-alloy-operator
    namespace: default
---
# Source: k8s-monitoring/charts/alloy-operator/templates/rbac/alloy-objects.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: k8smon-alloy-operator
  labels:
    helm.sh/chart: alloy-operator-0.3.8
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.2.1"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: k8smon-alloy-operator
subjects:
  - kind: ServiceAccount
    name: k8smon-alloy-operator
    namespace: default
---
# Source: k8s-monitoring/charts/alloy-operator/templates/rbac/leader-election.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: k8smon-alloy-operator-leader-election-role
  namespace: default
  labels:
    helm.sh/chart: alloy-operator-0.3.8
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.2.1"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - get
      - list
      - watch
      - create
      - update
      - patch
      - delete
  - apiGroups:
      - coordination.k8s.io
    resources:
      - leases
    verbs:
      - get
      - list
      - watch
      - create
      - update
      - patch
      - delete
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
      - patch
---
# Source: k8s-monitoring/charts/alloy-operator/templates/rbac/leader-election.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: k8smon-alloy-operator-leader-election-rolebinding
  namespace: default
  labels:
    helm.sh/chart: alloy-operator-0.3.8
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.2.1"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: k8smon-alloy-operator-leader-election-role
subjects:
  - kind: ServiceAccount
    name: k8smon-alloy-operator
    namespace: default
---
# Source: k8s-monitoring/charts/alloy-operator/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: k8smon-alloy-operator
  namespace: default
  labels:
    helm.sh/chart: alloy-operator-0.3.8
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.2.1"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 8081
      targetPort: http
      protocol: TCP
    - name: metrics
      port: 8082
      targetPort: metrics
      protocol: TCP
  selector:
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
---
# Source: k8s-monitoring/charts/alloy-operator/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: k8smon-alloy-operator
  namespace: default
  labels:
    helm.sh/chart: alloy-operator-0.3.8
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.2.1"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: alloy-operator
      app.kubernetes.io/instance: k8smon
  template:
    metadata:
      labels:
        helm.sh/chart: alloy-operator-0.3.8
        app.kubernetes.io/name: alloy-operator
        app.kubernetes.io/instance: k8smon
        app.kubernetes.io/version: "1.2.1"
        app.kubernetes.io/managed-by: Helm
    spec:
      serviceAccountName: k8smon-alloy-operator
      containers:
        - name: alloy-operator
          image: "ghcr.io/grafana/alloy-operator:1.2.1"
          imagePullPolicy: IfNotPresent
          args:
            - --health-probe-bind-address=:8081
            - --metrics-bind-address=:8082
            - --leader-elect
            - --leader-election-id=k8smon-alloy-operator

          ports:
            - name: http
              containerPort: 8081
              protocol: TCP
            - name: metrics
              containerPort: 8082
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /healthz
              port: 8081
            initialDelaySeconds: 15
            periodSeconds: 20
          readinessProbe:
            httpGet:
              path: /readyz
              port: 8081
            initialDelaySeconds: 5
            periodSeconds: 10
          resources:
            limits: {}
            requests: {}
          securityContext:
            runAsNonRoot: true
      nodeSelector:
        kubernetes.io/os: linux
---
# Source: k8s-monitoring/templates/alloy.yaml
apiVersion: collectors.grafana.com/v1alpha1
kind: Alloy
metadata:
  name: k8smon-alloy-profiles
  namespace: default
spec: 
  alloy:
    clustering:
      enabled: false
      name: ""
      portName: http
    configMap:
      content: ""
      create: false
      key: null
      name: null
    enableReporting: true
    envFrom: []
    extraArgs: []
    extraEnv: []
    extraPorts: []
    hostAliases: []
    lifecycle: {}
    listenAddr: 0.0.0.0
    listenPort: 12345
    listenScheme: HTTP
    livenessProbe: {}
    mounts:
      dockercontainers: false
      extra: []
      varlog: false
    resources: {}
    securityContext:
      allowPrivilegeEscalation: true
      capabilities:
        add:
        - CHOWN
        - DAC_OVERRIDE
        - FOWNER
        - FSETID
        - KILL
        - SETGID
        - SETUID
        - SETPCAP
        - NET_BIND_SERVICE
        - NET_RAW
        - SYS_CHROOT
        - MKNOD
        - AUDIT_WRITE
        - SETFCAP
        drop:
        - ALL
      privileged: true
      runAsGroup: 0
      runAsUser: 0
      seccompProfile:
        type: RuntimeDefault
    stabilityLevel: generally-available
    storagePath: /tmp/alloy
    uiPathPrefix: /
  configReloader:
    customArgs: []
    enabled: true
    image:
      digest: ""
      registry: quay.io
      repository: prometheus-operator/prometheus-config-reloader
      tag: v0.81.0
    resources:
      requests:
        cpu: 10m
        memory: 50Mi
    securityContext: {}
  controller:
    affinity: {}
    autoscaling:
      enabled: false
      horizontal:
        enabled: false
        maxReplicas: 5
        minReplicas: 1
        scaleDown:
          policies: []
          selectPolicy: Max
          stabilizationWindowSeconds: 300
        scaleUp:
          policies: []
          selectPolicy: Max
          stabilizationWindowSeconds: 0
        targetCPUUtilizationPercentage: 0
        targetMemoryUtilizationPercentage: 80
      maxReplicas: 5
      minReplicas: 1
      scaleDown:
        policies: []
        selectPolicy: Max
        stabilizationWindowSeconds: 300
      scaleUp:
        policies: []
        selectPolicy: Max
        stabilizationWindowSeconds: 0
      targetCPUUtilizationPercentage: 0
      targetMemoryUtilizationPercentage: 80
      vertical:
        enabled: false
        recommenders: []
        resourcePolicy:
          containerPolicies:
          - containerName: alloy
            controlledResources:
            - cpu
            - memory
            controlledValues: RequestsAndLimits
            maxAllowed: {}
            minAllowed: {}
        updatePolicy: null
    dnsPolicy: ClusterFirst
    enableStatefulSetAutoDeletePVC: false
    extraAnnotations: {}
    extraContainers: []
    hostNetwork: false
    hostPID: true
    initContainers: []
    nodeSelector:
      kubernetes.io/os: linux
    parallelRollout: true
    podAnnotations:
      k8s.grafana.com/logs.job: integrations/alloy
    podDisruptionBudget:
      enabled: false
      maxUnavailable: null
      minAvailable: null
    podLabels: {}
    priorityClassName: ""
    replicas: 1
    terminationGracePeriodSeconds: null
    tolerations: []
    topologySpreadConstraints: []
    type: daemonset
    updateStrategy: {}
    volumeClaimTemplates: []
    volumes:
      extra: []
  crds:
    create: false
  extraObjects: []
  global:
    image:
      pullSecrets: []
      registry: ""
    podSecurityContext: {}
  image:
    digest: null
    pullPolicy: IfNotPresent
    pullSecrets: []
    registry: docker.io
    repository: grafana/alloy
    tag: null
  ingress:
    annotations: {}
    enabled: false
    extraPaths: []
    faroPort: 12347
    hosts:
    - chart-example.local
    labels: {}
    path: /
    pathType: Prefix
    tls: []
  nameOverride: alloy-profiles
  rbac:
    create: true
  service:
    annotations: {}
    clusterIP: ""
    enabled: true
    internalTrafficPolicy: Cluster
    nodePort: 31128
    type: ClusterIP
  serviceAccount:
    additionalLabels: {}
    annotations: {}
    automountServiceAccountToken: true
    create: true
    name: null
  serviceMonitor:
    additionalLabels: {}
    enabled: false
    interval: ""
    metricRelabelings: []
    relabelings: []
    tlsConfig: {}
---
# Source: k8s-monitoring/templates/extra-objects.yaml
apiVersion: collectors.grafana.com/v1alpha1
kind: Alloy
metadata:
  name: profile-source
spec:
  alloy:
    extraPorts:
    - appProtocol: h2c
      name: faro
      port: 12347
      protocol: TCP
      targetPort: 12347
  controller:
    podAnnotations:
      profiles.grafana.com/memory.container: alloy
      profiles.grafana.com/memory.path: /debug/pprof/heap
      profiles.grafana.com/memory.port: "12345"
      profiles.grafana.com/memory.scrape: "true"
