---
# Source: k8s-monitoring/charts/alloy-operator/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: k8smon-alloy-operator
  namespace: default
  labels:
    helm.sh/chart: alloy-operator-0.3.4
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.1.2"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
---
# Source: k8s-monitoring/charts/privateDatasourceConnect/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: k8smon-privatedatasourceconnect
  labels:
    app.kubernetes.io/name: pdc-agent
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/component: pdc-agent
type: Opaque
data:
  token: dGVzdC1wZGMtdG9rZW4tMTIzNDU=
  hosted-grafana-id: OTk5OTk5
  cluster: dGVzdC1jbHVzdGVy
---
# Source: k8s-monitoring/charts/alloy-operator/templates/rbac/alloy-manager.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: k8smon-alloy-operator-alloy-manager
  labels:
    helm.sh/chart: alloy-operator-0.3.4
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.1.2"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - collectors.grafana.com
    resources:
      - alloys
      - alloys/status
      - alloys/finalizers
    verbs:
      - create
      - delete
      - get
      - list
      - patch
      - update
      - watch
---
# Source: k8s-monitoring/charts/alloy-operator/templates/rbac/alloy-objects.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: k8smon-alloy-operator
rules:
  # Rules which allow the management of ConfigMaps, ServiceAccounts, and Services.
  - apiGroups: [""]
    resources: ["configmaps", "secrets", "serviceaccounts", "services"]
    verbs: ["*"]
  # Rules which allow the management of DaemonSets, Deployments, and StatefulSets.
  - apiGroups: ["apps"]
    resources: ["daemonsets", "deployments", "statefulsets"]
    verbs: ["*"]
  # Rules which allow the management of Horizontal Pod Autoscalers.
  - apiGroups: ["autoscaling"]
    resources: ["horizontalpodautoscalers"]
    verbs: ["*"]
  # Rules which allow the management of Ingresses and NetworkPolicies.
  - apiGroups: ["networking.k8s.io"]
    resources: ["ingresses", "networkpolicies"]
    verbs: ["*"]
  # Rules which allow the management of PodDisruptionBudgets.
  - apiGroups: ["policy"]
    resources: ["poddisruptionbudgets"]
    verbs: ["*"]
  # Rules which allow the management of ClusterRoles and ClusterRoleBindings.
  - apiGroups: ["rbac.authorization.k8s.io"]
    resources: ["clusterroles", "clusterrolebindings"]
    verbs: ["*"]
---
# Source: k8s-monitoring/charts/alloy-operator/templates/rbac/alloy-manager.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: k8smon-alloy-operator-alloy-manager
  labels:
    helm.sh/chart: alloy-operator-0.3.4
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.1.2"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: k8smon-alloy-operator-alloy-manager
subjects:
  - kind: ServiceAccount
    name: k8smon-alloy-operator
    namespace: default
---
# Source: k8s-monitoring/charts/alloy-operator/templates/rbac/alloy-objects.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: k8smon-alloy-operator
  labels:
    helm.sh/chart: alloy-operator-0.3.4
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.1.2"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: k8smon-alloy-operator
subjects:
  - kind: ServiceAccount
    name: k8smon-alloy-operator
    namespace: default
---
# Source: k8s-monitoring/charts/alloy-operator/templates/rbac/leader-election.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: k8smon-alloy-operator-leader-election-role
  namespace: default
  labels:
    helm.sh/chart: alloy-operator-0.3.4
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.1.2"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - get
      - list
      - watch
      - create
      - update
      - patch
      - delete
  - apiGroups:
      - coordination.k8s.io
    resources:
      - leases
    verbs:
      - get
      - list
      - watch
      - create
      - update
      - patch
      - delete
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
      - patch
---
# Source: k8s-monitoring/charts/alloy-operator/templates/rbac/leader-election.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: k8smon-alloy-operator-leader-election-rolebinding
  namespace: default
  labels:
    helm.sh/chart: alloy-operator-0.3.4
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.1.2"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: k8smon-alloy-operator-leader-election-role
subjects:
  - kind: ServiceAccount
    name: k8smon-alloy-operator
    namespace: default
---
# Source: k8s-monitoring/charts/alloy-operator/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: k8smon-alloy-operator
  namespace: default
  labels:
    helm.sh/chart: alloy-operator-0.3.4
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.1.2"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 8081
      targetPort: http
      protocol: TCP
    - name: metrics
      port: 8082
      targetPort: metrics
      protocol: TCP
  selector:
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
---
# Source: k8s-monitoring/charts/alloy-operator/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: k8smon-alloy-operator
  namespace: default
  labels:
    helm.sh/chart: alloy-operator-0.3.4
    app.kubernetes.io/name: alloy-operator
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/version: "1.1.2"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: alloy-operator
      app.kubernetes.io/instance: k8smon
  template:
    metadata:
      labels:
        helm.sh/chart: alloy-operator-0.3.4
        app.kubernetes.io/name: alloy-operator
        app.kubernetes.io/instance: k8smon
        app.kubernetes.io/version: "1.1.2"
        app.kubernetes.io/managed-by: Helm
    spec:
      serviceAccountName: k8smon-alloy-operator
      containers:
        - name: alloy-operator
          image: "ghcr.io/grafana/alloy-operator:1.1.2"
          imagePullPolicy: IfNotPresent
          args:
            - --leader-elect
            - --leader-election-id=k8smon-alloy-operator
            - --health-probe-bind-address=:8081
            - --metrics-bind-address=:8082
          ports:
            - name: http
              containerPort: 8081
              protocol: TCP
            - name: metrics
              containerPort: 8082
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /healthz
              port: 8081
            initialDelaySeconds: 15
            periodSeconds: 20
          readinessProbe:
            httpGet:
              path: /readyz
              port: 8081
            initialDelaySeconds: 5
            periodSeconds: 10
          resources:
            limits: {}
            requests: {}
          securityContext:
            runAsNonRoot: true
      nodeSelector:
        kubernetes.io/os: linux
---
# Source: k8s-monitoring/charts/privateDatasourceConnect/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: k8smon-privatedatasourceconnect
  labels:
    app.kubernetes.io/name: pdc-agent
    app.kubernetes.io/instance: k8smon
    app.kubernetes.io/component: pdc-agent
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: pdc-agent
      app.kubernetes.io/instance: k8smon
      app.kubernetes.io/component: pdc-agent
  template:
    metadata:
      labels:
        app.kubernetes.io/name: pdc-agent
        app.kubernetes.io/instance: k8smon
        app.kubernetes.io/component: pdc-agent
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: pdc-agent
                  app.kubernetes.io/instance: k8smon
                  app.kubernetes.io/component: pdc-agent
              topologyKey: kubernetes.io/hostname
      containers:
      - name: pdc-agent
        image: "grafana/pdc-agent:latest"
        imagePullPolicy: IfNotPresent
        args:
        - -token
        - $(GCLOUD_PDC_SIGNING_TOKEN)
        - -cluster
        - $(GCLOUD_PDC_CLUSTER)
        - -gcloud-hosted-grafana-id
        - $(GCLOUD_HOSTED_GRAFANA_ID)
        env:
        - name: GCLOUD_PDC_SIGNING_TOKEN
          valueFrom:
            secretKeyRef:
              name: k8smon-privatedatasourceconnect
              key: token
        - name: GCLOUD_HOSTED_GRAFANA_ID
          valueFrom:
            secretKeyRef:
              name: k8smon-privatedatasourceconnect
              key: hosted-grafana-id
        - name: GCLOUD_PDC_CLUSTER
          valueFrom:
            secretKeyRef:
              name: k8smon-privatedatasourceconnect
              key: cluster
        resources:
          limits:
            cpu: 100m
            memory: 512Mi
          requests:
            cpu: 50m
            memory: 256Mi
